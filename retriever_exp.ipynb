{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from rank_bm25 import BM25Okapi\n",
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "def load_json_data(data_dir):\n",
    "    \"\"\"\n",
    "    Load multiple JSON files from the folder and merge.\n",
    "    \"\"\"\n",
    "\n",
    "    files = glob(data_dir+\"/*.json\")\n",
    "    files.sort()\n",
    "    all_data = []\n",
    "    for file_path in files:\n",
    "        #print(\"Loading: \",file)\n",
    "        #file_path = os.path.join(data_dir, file)\n",
    "        with open(file_path, \"r\", encoding = \"utf-8-sig\") as f:\n",
    "            doc = json.load(f)\n",
    "        all_data.append(doc)\n",
    "        #all_data += doc\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = load_json_data('/Project/json_data/')\n",
    "\n",
    "documents = []\n",
    "for item in all_docs:\n",
    "    try:\n",
    "        documents.append(item['title'] + item['contents'])\n",
    "    except:\n",
    "        continue\n",
    "        documents.append(item['title'] + item['content'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_documents = [tokenizer.morphs(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BM25 index\n",
    "bm25 = BM25Okapi(tokenized_documents)\n",
    "\n",
    "# Save the BM25 index to a file\n",
    "with open('/Project/index_save_dir/sparse/bm25_index.pickle', 'wb') as index_file:\n",
    "    pickle.dump(bm25, index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BM25 index from a file\n",
    "with open('/Project/index_save_dir/sparse/bm25_index.pickle', 'rb') as index_file:\n",
    "    bm25 = pickle.load(index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "query = \"유럽 리그에서 활동중인 한국인 선수 이름은?\"\n",
    "\n",
    "# Tokenize the query\n",
    "tokenized_query = tokenizer.morphs(query)\n",
    "\n",
    "# Get the most relevant document indices\n",
    "doc_scores = bm25.get_scores(tokenized_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant passage: 이강인, 슛돌이에서 최연소 외국인 선수로…최초 U20 월드컵 MVP도\n",
      "/이강인 인스타그램 캡처[앵커]이강인 선수는  올해 스페인  프리메라리가에서 두 자릿수  공격포인트를 기록하며 리그 정상급 선수로  발돋움했습니다.  지난 2019년 열린 U20 월드컵에선  대한민국 남자선수로는  최초로 골든볼을  수상하기도 했습니다.  김창섭 기자입니다. [리포트]이강인은 지난 2007년 한 축구 예능 프로그램을 통해 대중에 이름을 알렸습니다. 이후 스페인으로 넘어가  발렌시아 유소년 아카데미에 입단해 유럽에서 축구 선수 생활을 시작했습니다. 이강인\"커서 형들과 같이 우리나라를 잘 이끌어서 좋은 선수가 되겠습니다.\" 2018년 발렌시아 1군으로 성인 무대에 데뷔했는데, 당시 나이는 만 17세 8개월 11일로 발렌시아 구단 역사상  최연소 외국인 선수로  기록된 바 있습니다. 이후 이강인은  2021년 마요르카로 이적한 뒤 벤치 선수에서 주전 선수로  도약을 거듭하게 됩니다. 이번 시즌  스페인 프리메라리가에서만 36경기를 출전해 6골 6도움으로  한국인 최초로 라리가에서 두 자릿수 공격 포인트를 기록하기도 했습니다.  약점으로 지적됐던  수비에서도 발군의 활약을 보이며 라리가 올해의 미드필더 후보에  오르기도 했습니다. 국가대표에서  이강인의 존재감은 더욱 큽니다. 지난 2019년 U20 월드컵에선 형들과 함께 출전해  팀의 준우승을 이끌었고, FIFA 주관 대회 최초의  한국인 골든볼 수상자로 이름을 남겼습니다.? 이강인\"앞으로도 더 좋은 선수가 돼서 대한민국 대표 선수로서 더 좋은 결과 나오고 좋은 모습 보여드리도록 노력하겠습니다\" 지난해 열린 카타르 월드컵에서도 막판 대표팀에 승선해  조규성의 그림 같은 헤딩골을  이끌어 내기도 했습니다. TV조선 김창섭입니다.\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "Most relevant passage: ‘학업+축구 병행 도전’ 강민우, 캐나다 대학-세미프로 입단\n",
      "이랜드 U-18 출신 강민우, 캐나다 리그 진출톰슨 리버스 대학에서 학업도 병행대학 리그와 소속 리그 두 곳에서 활동 예정2004년생의 강민우(리버스FC)가 캐나다 무대에서 축구와 학업 병행에 도전한다. 사진=리버스FC[이데일리 스타in 허윤수 기자] 19세의 대한민국 소년이 해외에서 새로운 축구의 장을 열고자 한다.캐나다 리그1 BC(3부리그)의 리버스FC는 25일(이하 한국시간) 한국인 미드필더 강민우 영입을 발표했다. 2004년생으로 K리그2 서울 이랜드의 18세 이하(U-18) 팀을 거친 강민우는 패스 능력과 빠른 상황 판단에 강점을 보인다. 주로 공격형 미드필더 자리에 서지만 수비형 미드필더와 윙백까지 뛸 수 있는 다재다능한 자원이다.강민우는 프로팀 우선 지명을 받았지만 일반적인 선수들과 다른 길을 선택했다. 그는 리버스FC에 몸담으면서 캠룹스의 톰슨 리버스 대학교에도 소속됐다. 즉 축구와 학업을 병행하는 결정을 내렸다.톰슨 리버스 대학에서도 공부만 하는 게 아니다. 선수 생활도 함께한다. 대학팀 소속으로 대학교 리그인 U 스포츠 리그에서 경쟁한다. 동시에 리버스FC에서는 세미 프로 무대에 나선다. 톰슨 리버스 대학과 리버스FC가 같은 리그에 속하지 않았기에 가능한 활동이다.리버스 FC는 리그1 BC에 속했다. 캐나다는 지난 2019년 2028 북중미 월드컵을 앞두고 1부리그인 캐네디언 프리미어리그(CPL)를 출범했다. 그다음 무대가 리그1 BC다. 현재 2부리그가 없는 상황이기에 사실상 그 역할을 맡고 있다.고등학교를 졸업한 선수들이 유학을 위해 해외에서 운동과 학업을 병행하는 경우는 종종 있다. 강민우의 사례가 조금 더 눈에 띄는 건 대학팀과 소속팀에서 모두 경기에 나서기 때문이다. 그러면서도 경영학, 법학 전공 등에 관심을 보일 정도로 학업에 대한 열정도 뜨거운 것으로알려졌다.톰슨 리버스 대학과 리버스FC를 동시에 관리하는 존 안툴로프 감독은 강민우에 대해 “좋은 선수라 팀에 많은 도움이 될 거 같다”며 “성실하고 프로다운 모습을 기대한다”고 말했다.한편 강민우의 리버스FC 속한 리그1 BC는 오는 30일 개막한다. 미국 메이저리그사커(MLS)의 밴쿠버 화이트캡스 리저브 팀을 포함해 8개 팀이 자웅을 겨룬다.\n",
      "\n",
      "Most relevant passage: 이강인의 PSG행이 갖는 의미\n",
      "[주장] 상위무대에서 정상 밟을 수 있는 기회, 치열한 경쟁 불가피또 한 명의 초대형 한국인 유럽파가 탄생했다. '골든보이' 이강인(22)이 마침내 프랑스 명문 파리 생제르맹에 공식 입성했다.?프랑스 리그앙 파리 생제르맹(이하 PSG)은 지난 7월 9일 이강인의 영입을 공식 발표했다. 계약 기간은 2028년까지이며 구체적인 계약 내용은 이적료는 공개하지 않았지만 현지 언론은 약 2200만유로(약 314억원)의 이적료에 이 중 약 20%가 이강인에게 돌아가며, 연봉은 약 400만유로(약 57억원) 수준이라고 보도하고 있다. 전 소속팀 마요르카에서 약 50만유로 정도를 받았던 것을 감안하면 2년 사이에 8배가 폭등한 것이다.?유럽에서 손꼽히는 빅클럽?▲ ?사진은 파리 생제르맹 홈페이지 메인 화면을 장식한 이강인.ⓒ 파리 생제르맹 구단 홈페이지?프랑스의 수도인 파리를 연고로 하는 PSG는, 1970년에 기존의 두 클럽인 스타드 생제르맹과 파리 FC를 병합하면서 출발했다. 비교적 짧은 역사에 2010년대 이전만 해도 리그 우승은 두 번뿐이었지만, 2011년 카타르 왕실 자본인 '카타르 스포츠 인베스트먼츠'에 인수된 이후 일약 '오일머니' 파워를 앞세워 세계적인 선수들을 싹쓸이하면서 일약 유럽에서 손꼽히는 빅클럽으로 성장했다.?PSG는 2010년대 이후에만 9번의 우승을 추가하며 리그앙 통산 최다 우승팀(11회)의 반열에 올랐다. 각종 컵대회까지 합치면 카타르 인수 이후 수집한 우승트로피는 무려 30개에 이른다. 리오넬 메시(아르헨티나)를 비롯하여 킬리안 음바페(프랑스), 네이마르-티아고 실바(브라질), 즐라탄 이브라히모비치(스웨덴), 앙헬 디 마리아(아르헨티나), 에딘손 카바니(우루과이) 등 쟁쟁한 월드클래스 슈퍼스타들이 대거 PSG를 거쳐갔다.?하지만 흔히 유럽을 대표하는 최고 빅클럽으로 꼽히는 레알 마드리드, 바르셀로나, 바이에른 뮌헨, 맨체스터 시티같은 구단에 비하여 유일한 아쉬움은 아직 유럽 챔피언스리그(UCL) 우승 트로피를 들어올리지 못했다는 것. 2019-20시즌에 결승까지 올랐으나 바이에른의 벽을 넘지 못하고 준우승에 머물렀다. 최근 두 시즌 동안은 메시-네이마르-음바페라는 역대급 조합을 구축하고도 내리 UCL 16강에 머물며 자국리그 내에서만 강한 '리그앙 여포'라는 조롱을 듣기도 했다.?이강인은 만 6세였던 2007년 축구 예능 KBS2 <날아라 슛돌이>를 통해 처음 이름을 알렸고, 다시 어린 나이에도 남다른 재능으로 '축구 신동'이라는 평가를 받았다. 정식으로 축구에 입문한 2011년부터 발렌시아 유소년팀에 합류했고, 7년 뒤인 2018년 17세 나이로 프로에 데뷔했다. 2021년에는 마요르카로 이적하며 줄곧 스페인에서 뛰어왔다. 라 리가에서의 통산 성적은 5시즌 동안 컵대회 포함 17골 19도움이다.?특히 마요르카에서의 2022-23시즌은 이강인이 성인무대에서 한 단계 스텝업한 시즌으로 꼽힌다. 이강인은 마요르카의 에이스로 활약하며 각종대회에서 총 39경기에서 나서서 6골 6도움으로 프로 두 자릿수 공격포인트를 달성하는 데 성공했다. 경기당 키 패스 1.5회, 드리블 성공 2.5회로 내용 면에서 우수한 지표를 보여주며 라 리가 상위권의 공격 자원으로 활약했다.?국가대표팀에도 꾸준히 소집되어 2019 폴란드 U-20월드컵에서는 한국대표팀을 역대 최고 성적인 준우승으로 이끌며 FIFA 주관 대회 한국인 선수 첫 골든볼(최우수선수) 수상의 영광을 안았다. 성인대표팀에서도 A매치 통산 14경기에 출전했고, 2022 카타르월드컵에서는 2도움을 올리며 한국의 16강을 견인하는 등, 손흥민을 잇는 한국대표팀의 차세대 에이스로 꼽히고 있다.?이강인의 PSG행은 선수 개인에게나 한국축구로서나 모두 기념비적인 의미를 지닌다. 한국을 비롯한 아시아 선수가 유럽 최정상 수준의 빅클럽에서 뛴다는 것은 예나 지금이나 드문 사례다.?프랑스 리그1은 스페인 라리가에 비하여 전체적인 리그 위상은 낮지만 역시 유럽 상위 5대리그로 인정받는 빅리그다. 클럽의 규모와 위상면에서는 이강인이 스페인에서 뛰었던 발렌시아나 마요르카와는 비교가 불가능한 정도다. UEFA(유럽축구연맹)이 소속 클럽들의 성적과 위상 및 가치를 종합하여 집계한 클럽랭킹에 따르면, 영입 시점을 기준으로 이강인은 '역대 한국인 선수중 가장 높은 위상의 팀'에서 뛰게 되는 타이 기록을 세웠다.정상을 밟을 수 있는 기회?2023년 현재 PSG의 클럽랭킹은 유럽 전체구단중 6위다. 현재 1위는 맨시티(잉글랜드)이며 바이에른(독일), 첼시-리버풀(잉글랜드), 레알 마드리드(스페인) 순이다. PSG는 프랑스리그 소속팀 중 유일하게 20위권 이내에 이름을 올렸으며, 이는 세계적인 명문으로 유명한 맨유(잉글랜드)-유벤투스(이탈리아)-바르셀로나(스페인)보다도 높다.?이강인 이전에 한국인 선수의 영입 시점에서 UEFA 클럽랭킹이 가장 높았던 구단은 2005년 박지성이 뛰었던 맨유, 2011년 박주영의 아스널로 모두 영입 시점의 클럽 랭킹은 6위였다. 현재 한국축구의 간판인 손흥민이 2015년 토트넘(잉글랜드)에 입단할 당시 랭킹은 21위였고, 김민재가 지난해 입단할 당시의 SSC 나폴리(이탈리아)는 25위였다. 다만 김민재가 현재 UEFA 랭킹 2위 바이에른 뮌헨 입단을 앞두고 있어서 이강인의 기록은 경신될 가능성이 높다.?'한국축구의 기대주'로 꼽히는 이강인의 PSG행이 기대되는 이유는 리그 앙과 유럽챔피언스리그같은 상위무대에서 활약하며 정상을 밟을 수 있는 기회 때문이다. 이강인은 프로무대에서 아직까지 우승과는 인연이 없었다. 그가 스페인에서 뛰었던 발렌시아나 마요르카는 우승권가 거리가 멀었고, 약한 팀전력과 어수선한 내부사정 등으로 이강인이 더 큰 야망을 꿈꾸기에는 한계가 있었다.?하지만 PSG는 유럽에서 손꼽히는 구단인 데다가 출전한 모든 대회에서 우승을 목표로 할 수 있는 전력을 구축하고 있다. 2선에서 공격형 미드필더와 윙어가 주포지션인 이강인은 지난 시즌을 끝으로 PSG를 떠난 '리오넬 메시의 대체자'라는 상징성에서도 더 주목받고 있다.?더욱이?유럽에서 손꼽히는 빅클럽인 PSG의 위상과 전력을 감안할 때 자국리그는 기본이고 유럽클럽대항전 우승 기회도 노려볼 수 있다. 국가대표팀에서도 항저우 아시안게임과, 63년 만의 우승을 노리는 2023 아시안컵에 출전이 유력하고, 나이를 감안할 때 월드컵 본선에서도 2-3번 이상 출전이 가능한 만큼 이강인이 도전할 수 있는 목표는 많다.?물론 PSG에 입단했다고 장및빛 미래만 기다리고 있다는 보장은 없다. 현재 PSG는 이미 팀을 떠난 메시에 이어 에이스 음바페와 네이마르까지 이적설에 휘말려 있는 복잡한 상황이라 전력을 얼마나 유지할 수 있을지 장담하기 어렵다. 스타 선수들이 많지만 그만큼 끈끈한 조직력이나 팀워크에는 문제가 있다는 뒷말도 있다.?새롭게 PSG의 지휘봉을 잡은 루이스 엔리케 감독이 이강인을 어떤 포지션에서 활용할지도 아직 확실하지 않다. PSG는 언제든 스타급 선수를 데려올 수 있는 자금력을 갖춘 구단이다.이강인은 기존의 마르코 베라티-마누엘 우가르테 같은 미드필더들은 물론이고, 추가적인 선수 영입여부에 따라 어떤 포지션에 가더라도 치열한 경쟁이 불가피하다. 이미 발렌시아 시절, 애매한 포지션 문제와 주전경쟁의 어려움을 혹독하게 겪어본 적이 있는 이강인으로서는 초반부터 본인의 능력에 대한 신뢰를 심어주는 것이 무엇보다 중요하다.?한국팬들은 손흥민이나 박지성이 유럽 최고 수준의 무대에서 활약하는 모습을 지켜보면서 자부심을 느꼈고 열광했다. 이제는 이강인이 선배들의 아성을 이어서 축구팬들에게 또다른 감동을 선사할 수 있을까.\n",
      "\n",
      "Most relevant passage: 대단한 이강인의 기록…드리블·찬스메이킹 라리가 'TOP 3'\n",
      "마요르카 이강인이 24일 헤타페전에서 한국인 선수 최초로 스페인 프리메라리가 멀티골을 기록한 뒤 골 세리머니를 펼치고 있다. EPA=연합뉴스이강인(22·마요르카)이 스페인 프리메라리가 전체 선수들 가운데 드리블 성공 횟수와 빅찬스 메이킹 모두 최상위권에 속한 것으로 집계됐다. 두 지표 모두 최상위권인 선수는 이강인과 레알 마드리드의 비니시우스 주니오르(23) 단 두 명뿐이다.24일 소파스코어에 따르면 이강인은 이번 시즌 리그에서 드리블 성공 횟수가 60회에 달한다. 이는 비니시우스 주니오르(90회), 사무엘 추쿠에제(비야레알·70회)에 이어 공동 3위다. 라리가가 유럽에서도 가장 기술이 강조되는 리그라는 점에서 이강인이 톱3에 이름을 올린 건 더욱 눈에 띄는 기록일 수밖에 없다.실제 이강인은 경기 내내 화려한 드리블로 상대 수비를 제치거나 탈압박에 나서는 등 화려한 발기술이 강점이다. 그리고 그 드리블이 라리가에서도 확실하게 돋보이는 수준이라는 점은 이강인의 클래스를 엿볼 수 있는 대목이다.마요르카 이강인(왼쪽)이 24일 헤타페전에서 한국인 선수 최초로 스페인 프리메라리가 멀티골을 기록한 뒤 골 세리머니를 펼치고 있다. EPA=연합뉴스비단 개인 기술뿐만이 아니다. 이강인은 패스를 통해 결정적인 기회를 만드는 빅찬스 메이킹에서도 리그 최상위권이다. 이강인은 이번 시즌 12차례나 결정적인 기회를 만들었다. 앙투안 그리즈만(아틀레티코 마드리드·15회)에 이어 공동 2위에 해당하는 기록이다.이강인과 더불어 하피냐(바르셀로나) 세르지 다르데르(에스파뇰) 그리고 비니시우스 주니오르가 공동 2위에 올라 있다. 앞서 드리블, 그리고 찬스메이킹 모두 톱3에 속한 선수는 세계적인 공격수 반열에 오른 비니시우스 주니오르와 이강인, 두 명뿐이다.뿐만 아니라 이강인은 정확하게 전달된 크로스도 47회로 리그 2번째로 많았고, 슈팅으로 이어진 키패스는 46회, 볼 경합 승리 횟수는 158회로 각각 11위였다. 세계적인 선수들이 즐비한 라리가에서도 각종 지표 최상위권에 이름을 올리고 있다. 잉글랜드 프리미어리그(EPL) 등 다른 리그의 러브콜이 쏟아지는 배경이기도 하다.김명석 기자 clear@edaily.co.kr\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "Most relevant passage: 슛돌이, 메시 빈자리 메운다…음바페·네이마르와 한솥밥\n",
      "이강인, PSG로 이적 5년 계약- 구단 첫 한국인… 등번호 19번- 이적료 311억 추정 韓 역대 2위‘슛돌이’ 꼬마가 세계적인 명문 클럽에서 ‘축구의 신’ 리오넬 메시(아르헨티나)를 대신해 월드클래스 선수들과 호흡을 맞춘다.9일 프랑스 프로축구 파리 생제르맹에 입단한 이강인이 자신의 유니폼에 사인을 하고 있다.  파리 생제르맹 홈페이지 캡처프랑스 프로축구 리그1 파리 생제르맹(PSG)은 9일(한국시간) 구단 홈페이지를 통해 “(이강인의 원 소속팀인) 마요르카와 이적 작업을 마무리했다. 이강인과 2028년까지 계약했다”고 발표했다. 이로써 이강인은 PSG에서 뛰는 첫 한국인 선수로 이름을 올렸다. 등번호는 마요르카에서 달았던 19번을 그대로 이어갔다.이적료는 공개되지 않았으나 2200만 유로(약 311억 원)로 추정된다. 이는 손흥민(토트넘)이 2015년 8월 레버쿠젠(독일)에서 토트넘으로 이적할 당시 기록한 3000만 유로(약 426억 원)에 이어 역대 한국인 선수 이적료 액수로는 두 번째에 해당된다. 음바페PSG는 네이마르를 비롯해 킬리안 음바페, 마르키뇨스, 파비안 루이스 등 월드클래스 선수들이 즐비한 프랑스 최강 클럽이다. 2011년 카타르 왕족 자본이 인수한 이후 지난 시즌까지 무려 9차례 리그 우승을 차지했다. 언제든지 유럽축구연맹 챔피언스리그(UCL) 우승을 노릴 수 있는 강팀이다.PSG는 지난 시즌까지 ‘MNM(메시-네이마르-음바페) 트리오’가 공격을 이끌었는데, 메시가 최근 미국프로축구 인터 마이애미로 이적하면서 새로운 공격 조합을 꾸려야 하는 상황이다. 이강인이 메시의 빈 자리를 메울 공산이 크다.이강인은 일찌감치 한국 축구의 미래로 손꼽혀 왔다. 2007년 방송 예능 프로그램 ‘날아라 슛돌이’에 출연하며 ‘신동’으로 이름을 알린 그는 2011년 7월 10살의 나이로 스페인 명문 발렌시아 유스팀에 입단했다. 2018년 10월 한국 선수 역대 최연소인 17세 327일의 나이로 코파 델 레이(국왕컵)를 통해 발렌시아 1군에 데뷔했다.2019년 국제축구연맹(FIFA) 20세 이하(U-20) 월드컵에서 대회 최우수선수인 ‘골든볼’을 받아 전 세계에 자신의 이름을 날린 이강인은 2021년 발렌시아를 떠나 마요르카에 둥지를 튼 이후 리그 정상급 선수로 발돋움했다. 이강인은 구단 홈페이지를 통해 “팀을 최대한 돕는 게 나의 임무”라며 “팀이 모든 경기에서 이기고 최대한 많은 우승 타이틀을 따내는 데 일조하고 싶다”고 소감을 밝혔다.\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "most_relevant_index = doc_scores.argmax()\n",
    "top_k = 5\n",
    "most_relevant_index = np.argpartition(doc_scores,-1*top_k)[-1*top_k:]\n",
    "\n",
    "# Retrieve the most relevant passage\n",
    "\n",
    "for i in most_relevant_index:\n",
    "  print(\"Most relevant passage:\",documents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: farm-haystack in /opt/conda/lib/python3.8/site-packages (1.20.0rc0)\n",
      "Requirement already satisfied: boilerpy3 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (1.0.6)\n",
      "Requirement already satisfied: canals==0.5.0 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (0.5.0)\n",
      "Requirement already satisfied: events in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (0.5)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (4.2.1)\n",
      "Requirement already satisfied: lazy-imports==0.3.1 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (0.3.1)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (10.1.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (2.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (2.0.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (8.2.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (3.9.1)\n",
      "Requirement already satisfied: posthog in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (3.0.1)\n",
      "Requirement already satisfied: prompthub-py==4.0.0 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (4.0.0)\n",
      "Requirement already satisfied: pydantic<2 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (1.10.12)\n",
      "Requirement already satisfied: quantulum3 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (0.9.0)\n",
      "Requirement already satisfied: rank-bm25 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (0.2.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (2.31.0)\n",
      "Requirement already satisfied: requests-cache<1.0.0 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (0.9.8)\n",
      "Requirement already satisfied: safetensors<0.3.2 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (0.3.1)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (1.3.0)\n",
      "Requirement already satisfied: sseclient-py in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (1.7.2)\n",
      "Requirement already satisfied: tenacity in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.2 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (0.4.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (4.62.3)\n",
      "Requirement already satisfied: transformers==4.31.0 in /opt/conda/lib/python3.8/site-packages (from farm-haystack) (4.31.0)\n",
      "Requirement already satisfied: pyyaml<7.0,>=6.0 in /opt/conda/lib/python3.8/site-packages (from prompthub-py==4.0.0->farm-haystack) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.31.0->farm-haystack) (3.3.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.31.0->farm-haystack) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.31.0->farm-haystack) (1.21.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.31.0->farm-haystack) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.31.0->farm-haystack) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.31.0->farm-haystack) (0.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from pydantic<2->farm-haystack) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->farm-haystack) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->farm-haystack) (3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->farm-haystack) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->farm-haystack) (2021.10.8)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /opt/conda/lib/python3.8/site-packages (from requests-cache<1.0.0->farm-haystack) (1.4.4)\n",
      "Requirement already satisfied: attrs>=21.2 in /opt/conda/lib/python3.8/site-packages (from requests-cache<1.0.0->farm-haystack) (21.2.0)\n",
      "Requirement already satisfied: cattrs>=22.2 in /opt/conda/lib/python3.8/site-packages (from requests-cache<1.0.0->farm-haystack) (23.1.2)\n",
      "Requirement already satisfied: url-normalize>=1.4 in /opt/conda/lib/python3.8/site-packages (from requests-cache<1.0.0->farm-haystack) (1.4.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=1.3.0->farm-haystack) (1.6.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=1.3.0->farm-haystack) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=1.3.0->farm-haystack) (3.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->farm-haystack) (0.18.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->farm-haystack) (5.4.0)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /opt/conda/lib/python3.8/site-packages (from networkx->farm-haystack) (5.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from pandas->farm-haystack) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->farm-haystack) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.8/site-packages (from pandas->farm-haystack) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from posthog->farm-haystack) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.8/site-packages (from posthog->farm-haystack) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.8/site-packages (from posthog->farm-haystack) (2.2.1)\n",
      "Requirement already satisfied: inflect in /opt/conda/lib/python3.8/site-packages (from quantulum3->farm-haystack) (7.0.0)\n",
      "Requirement already satisfied: num2words in /opt/conda/lib/python3.8/site-packages (from quantulum3->farm-haystack) (0.5.12)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.8/site-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack) (1.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0->farm-haystack) (2021.11.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema->farm-haystack) (3.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.31.0->farm-haystack) (3.0.5)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.8/site-packages (from num2words->quantulum3->farm-haystack) (0.6.2)\n",
      "\u001b[33mDEPRECATION: torch-tensorrt 1.0.0a0 has a non-standard dependency specifier torch>=1.9.0<1.11.0. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torch-tensorrt or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install farm-haystack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, BertModel\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "class KobertBiEncoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KobertBiEncoder, self).__init__()\n",
    "        \n",
    "        self.passage_encoder = BertModel.from_pretrained(\"skt/kobert-base-v1\")     \n",
    "        self.query_encoder = BertModel.from_pretrained(\"skt/kobert-base-v1\")\n",
    "            \n",
    "    def forward(\n",
    "        self, input_ids: torch.LongTensor, attention_mask: torch.LongTensor, type: str\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"passage 또는 query를 bert로 encoding합니다.\"\"\"\n",
    "\n",
    "        if type == \"passage\":\n",
    "            return self.passage_encoder(\n",
    "                input_ids=input_ids, attention_mask=attention_mask\n",
    "            ).pooler_output\n",
    "        else:\n",
    "            return self.query_encoder(\n",
    "                input_ids=input_ids, attention_mask=attention_mask\n",
    "            ).pooler_output\n",
    "\n",
    "    def checkpoint(self, model_ckpt_path):\n",
    "        torch.save(deepcopy(self.state_dict()), model_ckpt_path)\n",
    "\n",
    "    def load(self, model_ckpt_path):\n",
    "        with open(model_ckpt_path, \"rb\") as f:\n",
    "            state_dict = torch.load(f)\n",
    "        self.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KobertBiEncoder(\n",
       "  (passage_encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (query_encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "\n",
    "check_point_dir = '/Project/2050iter_model.pt'\n",
    "model = KobertBiEncoder()\n",
    "\n",
    "\n",
    "tokenizer = KoBERTTokenizer.from_pretrained(\"skt/kobert-base-v1\")\n",
    "model.load(\"/Project/2050iter_model.pt\")\n",
    "\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32 \n",
    "\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        tokenized_text = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length)\n",
    "        input_ids = torch.tensor(tokenized_text[\"input_ids\"])\n",
    "        attention_mask = torch.tensor(tokenized_text[\"attention_mask\"])\n",
    "        return input_ids, attention_mask\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    input_ids = [item[0] for item in batch]\n",
    "    attention_masks = [item[1] for item in batch]\n",
    "    input_ids = torch.stack(input_ids, dim=0)\n",
    "    attention_masks = torch.stack(attention_masks, dim=0)\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "def load_json_data(data_dir):\n",
    "    \"\"\"\n",
    "    Load multiple JSON files from the folder and merge.\n",
    "    \"\"\"\n",
    "\n",
    "    files = glob(data_dir+\"/*.json\")\n",
    "    files.sort()\n",
    "    all_data = []\n",
    "    for file_path in files:\n",
    "        #print(\"Loading: \",file)\n",
    "        #file_path = os.path.join(data_dir, file)\n",
    "        with open(file_path, \"r\", encoding = \"utf-8-sig\") as f:\n",
    "            doc = json.load(f)\n",
    "        all_data.append(doc)\n",
    "        #all_data += doc\n",
    "    return all_data\n",
    "\n",
    "data_dir = '/Project/json_data'\n",
    "all_docs = load_json_data(data_dir)\n",
    "use_content_type = 'All'\n",
    "\n",
    "if use_content_type == \"title\":\n",
    "    doc_content = [item['title'] for item in  all_docs]\n",
    "elif  use_content_type == \"content\":\n",
    "    doc_content = [item['contents'] for item in  all_docs]\n",
    "else:\n",
    "    doc_content = [item['title'] + item['contents'] for item in  all_docs]\n",
    "    \n",
    "doc_dataset = TextDataset(doc_content, tokenizer)\n",
    "doc_loader = DataLoader(doc_dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        collate_fn=collate_fn,\n",
    "                        shuffle = False\n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 850/850 [07:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish converting embeddings.\n",
      "Start building faiss index...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">17</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span>hidden_dim = doc_embedding.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span>dense_index = faiss.IndexFlatL2(hidden_dim)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span>dense_index.add(doc_embedding.cpu().numpy())                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>17 faiss.write_index(dense_index,faiss_save_path)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Finish building index.\"</span>)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'faiss_save_path'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m17\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0mhidden_dim = doc_embedding.shape[\u001b[94m1\u001b[0m]                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0mdense_index = faiss.IndexFlatL2(hidden_dim)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0mdense_index.add(doc_embedding.cpu().numpy())                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m17 faiss.write_index(dense_index,faiss_save_path)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mFinish building index.\u001b[0m\u001b[33m\"\u001b[0m)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'faiss_save_path'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "doc_embedding = []\n",
    "for batch in tqdm(doc_loader):\n",
    "    batch = tuple(t.cuda() for t in batch)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids = batch[0], attention_mask = batch[1], type = 'passage')\n",
    "    doc_embedding.append(output)\n",
    "doc_embedding = torch.cat(doc_embedding, dim=0)\n",
    "print(\"Finish converting embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building faiss index...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 # Build faiss index by using doc embedding</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Start building faiss index...\"</span>)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 7 hidden_dim = doc_embedding.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>dense_index = faiss.IndexFlatL2(hidden_dim)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>dense_index.add(doc_embedding.cpu().numpy())                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>faiss.write_index(dense_index,faiss_save_path)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'doc_embedding'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m# Build faiss index by using doc embedding\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mStart building faiss index...\u001b[0m\u001b[33m\"\u001b[0m)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 7 hidden_dim = doc_embedding.shape[\u001b[94m1\u001b[0m]                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0mdense_index = faiss.IndexFlatL2(hidden_dim)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0mdense_index.add(doc_embedding.cpu().numpy())                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0mfaiss.write_index(dense_index,faiss_save_path)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'doc_embedding'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "faiss_save_path = '/Project/index_save_dir/dense/faiss.index'\n",
    "\n",
    "# Build faiss index by using doc embedding\n",
    "print(\"Start building faiss index...\")\n",
    "hidden_dim = doc_embedding.shape[1]\n",
    "dense_index = faiss.IndexFlatL2(hidden_dim)\n",
    "dense_index.add(doc_embedding.cpu().numpy())\n",
    "faiss.write_index(dense_index,faiss_save_path)\n",
    "print(\"Finish building index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_save_dir = faiss_save_path\n",
    "dense_index = faiss.read_index(index_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '호날두의 소속팀은?'\n",
    "\n",
    "top_k = 5\n",
    "tokenized_text  = tokenizer(query, padding = 'max_length', truncation = True,\n",
    "                                max_length = 512, return_tensors = \"pt\")\n",
    "\n",
    "input_ids = tokenized_text[\"input_ids\"].cuda()\n",
    "attention_mask = tokenized_text[\"attention_mask\"].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    query_embed = model(input_ids = input_ids, attention_mask = attention_mask, type = 'query')\n",
    "\n",
    "query_embed = query_embed.detach().cpu().numpy()\n",
    "\n",
    "_,doc_id = dense_index.search(query_embed, top_k)\n",
    "\n",
    "cnt = 0\n",
    "raw_reference_list = []\n",
    "\n",
    "for i,id in enumerate(doc_id[0]):\n",
    "    raw_reference = all_docs[id]        \n",
    "    raw_reference_list.append(raw_reference)\n",
    "\n",
    "    cnt += 1\n",
    "    if (cnt == top_k) :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': \"PSG 이강인, '발렌시아 인연' 솔레르와 훈련 호흡 눈길\",\n",
       "  'url': 'https://sports.news.naver.com/news?oid=003&aid=0011970693',\n",
       "  'contents': \"\\n패스훈련·미니게임 등으로 적응 이어가[서울=뉴시스]PSG 구단은 13일(한국시간) 홈페이지를 통해 이강인이 합류한 후, 이틀째 훈련 모습을 약 3분짜리 영상으로 담아 공개했다. 이강인(왼쪽)과 솔레르가 스트레칭을 하고 있다. (사진 = PSG 홈페이지 캡처) *재판매 및 DB 금지[서울=뉴시스] 박지혁 기자 = 프랑스 프로축구 명문 파리 생제르맹(PSG) 유니폼을 입은 이강인(22)이 적응에 한창이다.PSG 구단은 13일(한국시간) 홈페이지를 통해 이강인이 합류한 후 이틀째 훈련 모습을 약 3분짜리 영상으로 담아 공개했다.전날 세계적인 스타 공격수 네이마르(브라질)와 나란히 마사지 침대에 자리한 모습이 담겨 화제를 모은 데 이어 이날은 '발렌시아 인연' 카를로스 솔레르(26·스페인)와 호흡이 눈길을 끌었다.스페인 국가대표 미드필더인 솔레르는 이강인보다 네 살 위로 지난해 2022 카타르월드컵에서 골을 터뜨렸던 실력파다. 이강인과는 과거 발렌시아(스페인)에서 한솥밥을 먹었다.솔레르는 발렌시아 유스 출신으로 2015년부터 지난해까지 발렌시아에서 뛰다가 PSG로 이적했다.이강인이 2011년 발렌시아 유스에 합류할 때부터 함께 해 2021년 마요르카(스페인)로 이적할 때까지 사실상 청소년기를 함께 보낸 진한 인연이다.둘은 밝은 표정으로 함께 훈련장에 입장하고, 스트레칭을 나란히 하며 계속 대화를 주고받았다. 훈련 이후 그라운드를 빠져나갈 때도 함께 했다. 이강인은 스페인어에 능통하다.이날 훈련에서 이강인은 강도 높은 패스 훈련과 미니 게임으로 구슬땀을 흘렸다. 루이스 엔리케 감독은 선수들을 독려하며 적극적으로 훈련을 이끌었다.전날 이강인과 나란히 있던 네이마르는 이날 영상에 보이지 않았다. 발목 부상 후유증으로 재활과 회복에 집중하는 것으로 전해졌다.또 한 명의 스타플레이어 킬리안 음바페(프랑스)도 없었다. 음바페의 경우 재계약과 관련해 구단과 불편한 기류가 흐르고 있다.이강인은 2028년까지 PSG와 계약을 맺었다.\\n\"},\n",
       " {'title': \"트루먼쇼 실사판...'방출 아픔 슛돌이' 이강인, 파리지앵 됐다\",\n",
       "  'url': 'https://sports.news.naver.com/news?oid=025&aid=0003292412',\n",
       "  'contents': '\\n  파리생제르맹에 입단한 이강인이 태극기를 펼쳐 보이고 있다. 사진 파리생제르맹 홈페이지       마침내 이강인(22)이 프랑스 파리생제르맹 유니폼을 입고 입단 사진을 찍는 ‘옷피셜(옷+오피셜)’이 떴다.        프랑스 프로축구 파리생제르맹은 9일(한국시간) “이강인과 2028년까지 (5년) 계약 했다. 등번호 19번을 다는 22세 공격형 미드필더는 구단 최초의 한국 선수”라고 발표했다. 이강인이 파리생제르맹 후원사인 명품 디올 수트를 입은 사진, 이강인이 태극기를 펼치고 있는 사진 등도 공개했다.       디올 수트를 입은 이강인. 사진 파리생제르맹 홈페이지       지난 7일 서울에서 축구선수 권창훈 결혼식이 참석했던 이강인은 8일 오전 인천공항을 통해 파리로 향했다. 파리생제르맹이 10일부터 프리시즌에 돌입하는 만큼 출국 일정을 앞당겼다. 파리 공항에서 포착된 이강인은 곧바로 파리생제르맹 구단으로 향해 공식 사인을 했다.        이강인 영입 발표를 예고한 파리생제르맹 인스타그램. 사진 파리생제르맹 인스타그램       앞서 파리생제르맹은 이날 소셜미디어에 펄럭이는 태극기, 휴대폰 속에 한글로 ‘여기는 파리’라고 적힌 사진을 올리며 이강인 영입 발표를 예고했다. 현재 파리생제르맹 홈페이지와 인스타그램은 이강인 사진으로 ‘도배’되어 있다.        이강인 사진으로 도배된 파리생제르맹 인스타그램. 사진 파리생제르맹 인스타그램 캡처       6살이던 2007년에 예능 ‘날아라 슛돌이’에 출연해 신동으로 이름을 알린 이강인은 10살이던 2011년 스페인 발렌시아에 입단했다. 2019년 9월 18세 나이로 스페인 라리가 데뷔골을 터트렸다. 그해 국제축구연맹(FIFA) 20세 이하 월드컵 준우승을 이끌며 골든볼을 수상해 ‘골든 보이’란 애칭도 얻었다.      그러나 발렌시아 주전경쟁에서 어려움을 겪었고 교체 아웃된 뒤 벤치에서 얼굴을 감싸며 좌절하기도 했다. 발렌시아는 2021년 라 리가의 Non-Eu(비유럽) 쿼터 3장을 초과하자, 이강인을 방출하다시피 FA(자유계약선수)로 내보냈다. 스페인 마요르카 유니폼을 입고 절치부심한 이강인은 60m 드리블골을 포함해 6골-6어시스트를 올렸고, 카타르월드컵에서 2골에 관여하면서 전세계에 재능을 알렸다.       스페인 아틀레티코 마드리드와 협상을 벌였지만 이적료가 맞지 않았다. 파리생제르맹의 루이스 캄포스 단장이 주도적으로 나서 이적료 약 2200만 유로(310억원)를 지불하며 영입 경쟁에서 승리했다. 토트넘 손흥민(400억원)에 이어 한국인 역대 이적료 2위에 해당하는 금액이다. 이적료 310억원 중 20%인 62억원은 이강인의 몫이다. 이강인이 2021년 발렌시아에서 마요르카로 이적할 당시 연봉을 5억7000만원만 받는 대신 추후 타 팀으로 이적할 경우 이적료의 20%를 받는 조항을 포함 시킨 게 ‘신의 한수’가 됐다. 이강인은 파리생제르맹에서 마요르카에서 받던 연봉의 10배인 400만 유로(57억원)를 수령하는 것으로 알려졌다.      이강인을 보내며 이적료 248억원을 챙긴 마요르카는 이날 한국어로 ‘강인 선수, 고마워요. 건승을 빌어요. 마요르카는 항상 강인을 반길 거에요’라고 감사를 전했다. 반면 이강인을 공짜로 내보낸 발렌시아는 이적료를 한 푼도 챙기지 못했다.       이강인과 작별하며 감사를 전한 마요르카. 사진 마요르카 인스타그램       발렌시아에서 방출 아픔을 겪었던 이강인은 2년 만에 파리에 사는 남자 파리지앵이 됐다. 프랑스 출신으로 국내에 활동 중인 방송인 파비앙에 따르면 파리생제르맹을 ‘피에스지(PSG)’로 줄여 읽는 건 영어식 표기다. 프랑스 팀인 만큼 프랑스어 발음인 ‘뻬 에스 졔’로 읽거나 풀네임 혹은 파리라고 부르는 게 좋다고 한다.      파리생제르맹은 유럽 챔피언스리그 우승에 도전할 수 있는 ‘럭셔리 빅클럽’이다. 2011년 카타르 스포츠 엔비스트먼트가 인수한 뒤 즐라탄 이브라히모비치, 데이비드 베컴, 앙헬 디 마리아, 킬리안 음바페, 네이마르, 리오넬 메시 등 수퍼스타들을 끌어모았다. 막대한 금액을 투자한 뒤 프랑스 리그1을 9차례나 제패했으나 정작 유럽 챔피언스리그 우승에는 번번이 실패했다. 메시가 미국 인터 마이애미로 떠난 새 시즌에는 이강인을 비롯해 밀란 슈크리니아르, 마르코 아센시오, 마누엘 우가르테 등을 영입해 팀 개편에 나섰다.         파리생제르맹에 입단한 이강인. 사진 파리생제르맹 홈페이지       음바페와 네이마르는 각각 스페인 레알 마드리드와 사우디아리비아 이적설이 나오고 있으나 둘 다 잔류할 경우 이강인과 한솥밥을 먹게 된다. 현란한 드리블과 정교한 킥, 창의성을 지닌 이강인이 이 둘과 호흡을 맞춘다면 공격 포인트가 훨씬 더 늘어날 가능성이 높다. 리그와 컵대회를 포함해 우승 트로피를 들어 올릴 확률도 훨씬 높아졌다. FC바르셀로나와 스페인 대표팀을 이끌었던 엔리케 감독과의 궁합도 괜찮을 것으로 보인다. 이강인은 10살 때 스페인으로 건너가 스페인어로 프리 토킹도 가능하다. 다만 파리생제르맹이 빅클럽인 만큼, 이강인은 첨예한 주전 경쟁이 불가피하다.       예능 ‘날아라 슛돌이’에 출연한 이강인의 어린 시절 사진 KBS 캡처.       이강인은 “세계에서 가장 큰 팀 중 하나이자 최고 선수들이 모인 팀에 합류해 기쁘다. 새로운 모험을 빨리 시작하고 싶다”면서 “난 양쪽 날개를 포함해 다양한 포지션을 소화할 수 있는 미드필더이며 공을 편안하게 다룰 줄 안다. 우승에 대한 욕심과 갈증이 많다. 팀을 도와 매 경기 승리하고 최대한 많은 우승 타이틀을 획득할 수 있도록 돕겠다”고 소감을 밝혔다.       이강인은 ‘날아라 슛돌이’ 출연 당시 고 유상철 감독의 지도를 받았다. 췌장암 투병을 했던 유 감독은 생전에 “건강한 일주일이 주어진다면 강인이의 경기를 현장에서 보고 싶다”는 소망을 드러낸 적이 있다. 이강인이 뛸 파리생제르맹 홈구장인 파르크 데 프랭스는 유상철이 선수 시절인 1998년 프랑스월드컵 벨기에전에서 골을 넣은 경기장이다. 이 정도면 영화 ‘트루먼 쇼’ 실사판이다. 팬들은 이강인의 성장 과정을 일거수일투족 생중계로 지켜보는 것처럼 열광하고 있다.     \\n'},\n",
       " {'title': 'FC바르셀로나, 4년만에 라리가 정상…메시 보내고 첫 우승',\n",
       "  'url': 'https://sports.news.naver.com/news?oid=001&aid=0013941968',\n",
       "  'contents': \"\\n레반도프스키 멀티골 앞세워 에스파뇰 4-2 완파'레전드' 에르난데스, 감독으로 첫 우승…선수시절 더하면 9번째  골 넣고 기뻐하는 레반도프스키[신화=연합뉴스](서울=연합뉴스) 안홍석 기자 = 스페인 프로축구 FC바르셀로나가 리오넬 메시(파리 생제르맹)와 결별하고서 처음으로 프리메라리가 챔피언에 올랐다.    바르셀로나는 15일(한국시간) 스페인 바르셀로나의 RCDE 스타디움에서 열린 에스파뇰과의 2022-2023시즌 프리메라리가 34라운드 원정 경기에서 4-2로 이겼다.    3연승을 달린 바르셀로나는 승점 85(27승 4무 3패)를 쌓아 2위 레알 마드리드(승점 71·22승 5무 7패)와 격차를 승점 14로 벌리며 남은 4경기 결과와 상관없이 리그 우승을 확정했다.    바르셀로나는 2018-2019시즌 이후 4년 만이자 통산 27번째 라리가 우승을 일궜다.    또 2021년 8월 메시를 파리 생제르맹(PSG)으로 떠나보낸 뒤 처음으로 라리가 정상에 올랐다.    2021년 11월 바르셀로나 지휘봉을 잡은 사비 에르난데스 감독도 부임 이후 처음으로 라리가 우승 트로피를 들어 올렸다.감독으로 첫 라리가 우승 이룬 에르난데스 감독(오른쪽)[AP=연합뉴스]    에르난데스 감독은 현역 시절 유럽 무대에서는 바르셀로나 한 팀에서만 뛴 '레전드'다.     2015년 알사드(카타르)로 이적하고 2019년 은퇴한 뒤 알사드 감독으로 지도자에 입문했다가 친정팀 바르셀로나를 이끌어왔다.    에르난데스 감독은 선수로는 8차례나 라리가 우승을 경험했다.    이날 '득점 기계' 로베르트 레반도프스키가 멀티골을 올리며 승리에 앞장섰다.    전반 11분 알레한드로 발데의 컷백을 문전에서 마무리해 선제골을 뽑았고, 전반 40분에는 하피냐가 오른쪽에서 넘겨준 땅볼 크로스를 슬라이딩하며 슈팅해 3-0을 만들었다.    그사이 전반 20분에 발데가 추가골을 넣었다.    전반에만 3골을 터뜨린 바르셀로나는 후반 8분 프렝키 더용의 긴 패스에 이은 쥘 쿤데의 헤더로 우승 축포를 터뜨렸다.    에스파뇰은 후반 28분 하비 푸아도, 추가시간 호셀루의 골로 2점을 만회하는 데 그쳤다.     ahs@yna.co.kr\\n\"},\n",
       " {'title': '로마노 기자 \"김민재 바이에른 뮌헨 이적 가장 가까워\"...\\'12년 연속 우승\\' 도전?',\n",
       "  'url': 'https://sports.news.naver.com/news?oid=117&aid=0003740027',\n",
       "  'contents': '\\n[마이데일리 = 이현호 기자] 김민재(26·나폴리)의 새 팀 후보 리스트에 바이에른 뮌헨이 추가됐다.‘스카이 스포츠’ 독일 방송은 15일(한국시간) “바이에른 뮌헨이 중앙 수비수를 물색하고 있다. 뤼카 에르난데스가 파리 생제르맹(PSG)으로 떠날 수 있기 때문에 그 자리에서 뛸 수 있는 센터백을 찾고 있다”고 전했다.김민재가 바로 그 주인공이다. 이 매체는 “바이에른 뮌헨은 나폴리에서 한 시즌 동안 눈부신 활약을 보여준 김민재를 영입하려고 한다”면서 “뤼카 에르난데스 이적은 확실해졌고, 또 다른 수비수 벵자맹 파바르도 이적할 수 있다”고 언급했다.유럽축구 이적시장 전문가 파브리시오 로마노 기자 역시 같은 소식을 전했다. 로마노 기자는 자신의 개인 채널을 통해 “당초 김민재는 맨체스터 유나이티드 이적에 가까웠다. 하지만 바이에른 뮌헨이 적극적으로 김민재 영입을 추진하기 시작했다. 현재는 바이에른 뮌헨이 가장 유력하다”고 설명했다.바이에른 뮌헨은 독일 분데스리가 절대 1강이다. 이번 2022-23시즌 분데스리가 최종전에서 극적으로 역전 우승을 차지하며 최근 11시즌 연속 우승이라는 대기록을 달성했다. 다음 시즌 유럽축구연맹(UEFA) 챔피언스리그(UCL) 출전권도 여유롭게 확보했다.바이에른 뮌헨은 1900년에 창단해 123주년을 맞은 명문 팀이다. 독일 분데스리가 우승을 무려 33회나 기록했다. 분데스리가 최다 우승팀이다. 또한 DFB 포칼 우승은 20회, 독일 슈퍼컵 우승은 10회 차지했다. 두 개 대회 모두 최다 우승팀이다.뿐만 아니라 유럽 챔피언스리그 우승은 6회 달성했다. 가장 최근 우승은 2019-20시즌 우승이다. 해당 시즌 결승에서 파리 생제르맹(PSG)을 꺾고 통산 6번째 유럽 챔피언 자리에 올랐다. 이처럼 바이에른 뮌헨은 매년 1개 이상의 우승컵을 수집하는 ‘단골 우승’ 팀이다.세간의 중심에 선 김민재는 15일 논산 육군훈련소에 입소한다. 이곳에서 3주간 기초군사훈련을 받고 나와서 다시 몸을 만들어야 한다. 지난 2018 자카르타·팔렘방 아시안게임에서 금메달을 획득한 그는 병역 특례를 받아서 기초군사훈련과 봉사활동을 이수하면 병역 의무를 마치게 된다.김민재에겐 바쁘면서도 설레는 여름이 될 전망이다.[김민재. 사진 = 게티이미지코리아](이현호 기자 hhhh@mydaily.co.kr)\\n'},\n",
       " {'title': '스페인 유일 발롱도르, 루이스 수아레스 별세… 바르셀로나-인터 밀란의 레전드',\n",
       "  'url': 'https://sports.news.naver.com/news?oid=477&aid=0000439463',\n",
       "  'contents': '\\n▲ 향년 88세로 별세한 루이스 수아레스의 발롱도르 수상 당시의 모습 ⓒ 바르셀로나 구단 공식[스포티비뉴스=조용운 기자] 스페인 축구의 유일한 발롱도르 수상자 루이스 수아레스가 별세했다. 향년 88세.수아레스가 현역 시절 몸담았던 인터 밀란은 9일(한국시간) 구단 홈페이지를 통해 별세 소식을 전하며 추모의 뜻을 밝혔다. 수아레스는 1950~60년대 전설적인 미드필더로 활약했다. 1935년 스페인 갈리시아 지방에서 태어난 수아레스는 1953년 지역 팀인 데포르티보 라 코루냐에서 프로에 데뷔했다. 2년 후 바르셀로나에 입단하며 전성기를 누렸다. 특히 바르셀로나에서 뛴 6년 동안 122경기 62골의 기록을 남긴 그는 라리가 우승 2회와 함께 1960년 발롱도르를 수상했다. 당시 헝가리의 전설적인 스트라이커 페렌츠 푸스카스를 제치고 황금공을 들었다. 아직도 스페인 축구 역사상 유일한 발롱도르 수상자로 굵직한 발자취를 남겼다. 이후 인터 밀란으로 이적한 수아레스는 10년간 256경기 42골을 터뜨리며 3차례 세리에A 우승과 유로피언컵 2회 우승을 견인했다. 인터 밀란 시절에도 발롱도르 포디움에 3회 오르는 경험을 했다. ▲ 스페인 축구 전설 루이스 수아레스가 향년 88세로 별세했다 ⓒ 마르카 캡쳐▲ 스페인 축구 전설 루이스 수아레스(오른쪽)가 향년 88세로 별세했다 ⓒ 마르카 캡쳐1973년 현역에서 물러난 뒤에는 20여년 지도자 생활을 했다. 인터 밀란에서만 3차례 감독을 지냈고 1988년부터 스페인 A대표팀을 맡아 1990 이탈리아 월드컵 16강 성적을 냈다. 1995년 현장을 떠난 수아레스는 밀라노에서 여생을 보냈다. 수아레스의 별세를 전한 스페인 언론 \\'마르카\\'는 \"스페인에서 태어나 많은 사랑을 받았지만 거의 평생을 이탈리아에서 살았다. 그럼에도 스페인은 2001년 그에게 왕립 스포츠 헌장을 수여했다\"며 \"이탈리아에서도 큰 존경과 사랑을 받았고 안녕을 고할 때까지 머물렀다\"고 설명했다. \\n'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_reference_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
