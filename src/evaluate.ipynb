{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "refine_query_prompt = '''\n",
    "\n",
    "{{#system~}}\n",
    "\n",
    "You are a human expert on football related knowledge.\n",
    "All you answers should be in Korean\n",
    "\n",
    "{{~/system~}}\n",
    "\n",
    "{{~#user}}\n",
    "\n",
    "You will be given a football relatd query.\n",
    "The query may not be in an appropriate form to be used in a LLM.\n",
    "Your job is to refine the query so that it can be used in a LLM.\n",
    "\n",
    "Query: {{query}}\n",
    "\n",
    "refined query: \n",
    "\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "\n",
    "{{gen \"refined_query\" max_tokens=300 temperature=0.0 n=1}}\n",
    "\n",
    "{{~/assistant}}\n",
    "\n",
    "'''\n"
=======
    "import pandas as pd"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance\n",
    "\n",
    "def generate_answer(model_name, api_key, prompt, **kwargs):\n",
    "    \n",
    "    llm = guidance.llms.OpenAI(\n",
    "                        model_name,#\"gpt-3.5-turbo\",#\"gpt-4\",#\"gpt-3.5-turbo\", \n",
    "                        caching=False,\n",
    "                        api_key = api_key,\n",
    "                        ) \n",
    "\n",
    "    guidance.llm = llm \n",
    "    \n",
    "    guidance.llm.cache.clear()\n",
    "\n",
    "    structure_program = guidance(prompt, silent = False,**kwargs)\n",
    "                            \n",
    "    res = structure_program()\n",
    "\n",
    "    return res"
=======
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('/Project/src/ChatGPT_3.5_주관적_aspect.csv')"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = '''\n",
    "\n",
    "{{#system~}}\n",
    "\n",
    "You are a human expert on football related knowledge.\n",
    "All you answers should be in Korean\n",
    "\n",
    "{{~/system~}}\n",
    "\n",
    "{{#user~}}\n",
    "\n",
    "You will be given a query related to Football.\n",
    "Answer the query based on your knowledge. Your answer must be short and concise.\n",
    "You must not add or fabricate information.\n",
    "\n",
    "Query: {{query}}\n",
    "\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "\n",
    "{{gen \"answer\" max_tokens=500 temperature=0.0 n=1}}\n",
    "\n",
    "{{~/assistant}}\n",
    "\n",
    "'''"
=======
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_FT_4 = pd.read_csv('/Project/src/ChatGPT_4.0_FT_주관적_aspect.csv')"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 31,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/html": [
       "<div id=\"guidance-stop-button-992c1891-99ea-4d42-94bd-7c1f688b8e74\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-992c1891-99ea-4d42-94bd-7c1f688b8e74\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are a human expert on football related knowledge.\n",
       "All you answers should be in Korean</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>\n",
       "\n",
       "You will be given a football relatd query.\n",
       "The query may not be in an appropriate form to be used in a LLM.\n",
       "Your job is to refine the query so that it can be used in a LLM.\n",
       "\n",
       "Query: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{query}}'>포메이션이란?</span>\n",
       "\n",
       "refined query:</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &quot;refined_query&quot; max_tokens=300 temperature=0.0 n=1}}'>&quot;축구에서 포메이션이란 무엇인가요?&quot;</span></div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"992c1891-99ea-4d42-94bd-7c1f688b8e74\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_answer(\"gpt-4\", \"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\", \n",
    "                refine_query_prompt, \n",
    "                query = \"포메이션이란?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-65dc0d45-272f-42ba-a806-1a36ed31f630\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-65dc0d45-272f-42ba-a806-1a36ed31f630\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are a human expert on football related knowledge.\n",
       "All you answers should be in Korean</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You will be given a query related to Football.\n",
       "Answer the query based on your knowledge. Your answer must be short and concise.\n",
       "You must not add or fabricate information.\n",
       "\n",
       "Query: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{query}}'>축구에서 포메이션이란 무엇인가요?</span></div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &quot;answer&quot; max_tokens=500 temperature=0.0 n=1}}'>축구에서 포메이션은 팀의 전략적인 배치를 의미합니다. 즉, 선수들이 경기장에서 어떤 위치를 차지하고, 어떤 역할을 수행할지를 결정하는 것입니다. 이는 공격과 수비, 그리고 전체적인 팀 플레이에 큰 영향을 미칩니다.</span></div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"65dc0d45-272f-42ba-a806-1a36ed31f630\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_answer(\"gpt-4\", \"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\", \n",
    "                default_prompt, \n",
    "                query = \"축구에서 포메이션이란 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = '/Project/src/outputs/revision/*/'\n",
    "files = glob(data_dir)\n",
    "files.sort()\n",
    "\n",
    "files = ['/Project/src/outputs/revision/GPT-3.5_BM25_News_NoRefine/', '/Project/src/outputs/revision/GPT-4_BM25_News_NoRefine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Project/src/QA_dataset.csv')\n",
    "original_df = df.loc[:60,['Question','Answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = ['Embedding_news_Conf_3.5', 'Embedding_news_No_Conf_3.5', 'Embedding_news_wiki_Conf_3.5',\n",
    "            'BM25_news_Conf_4', 'BM25_news_wiki_Conf_4',\n",
    "            'Embedding_news_Conf_4', 'Embedding_news_Conf_3_k_2', 'Embedding_news_Conf_3_k_1',\n",
    "            'Embedding_news_No_Conf_4', 'Embedding_news_No_Conf_4_No_refine', 'Embedding_news_wiki_Conf_4',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = [\n",
    "            'BM25_news_3.5_No_refined', 'BM25_news_4_No_refined',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Project/src/outputs/revision/GPT-3.5_BM25_News_NoRefine/',\n",
       " '/Project/src/outputs/revision/GPT-4_BM25_News_NoRefine']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def extract_number(s):\n",
    "    \"\"\" Extracts the first number from a string. \"\"\"\n",
    "    json_num = s.split('/')[-1].split('.')[0]\n",
    "    return int(json_num)\n",
    "\n",
    "short_list = []\n",
    "avg_duration = []\n",
    "conf_list = []\n",
    "\n",
    "for idx, exp in enumerate(files):\n",
    "\n",
    "    output_list = glob(os.path.join(exp,\"*.json\"))\n",
    "    output_list.sort(key=extract_number)\n",
    "    \n",
    "    answer_list = []\n",
    "    duration_list = []\n",
    "    conf = []\n",
    "    \n",
    "    for x in output_list:\n",
    "        if len(output_list) != 61:\n",
    "            answer_list= ['']*61\n",
    "            break\n",
    "        \n",
    "        short_list.append(idx)\n",
    "        \n",
    "        with open(x, \"r\", encoding = \"utf-8-sig\") as f:\n",
    "            doc = json.load(f)\n",
    "\n",
    "        answer = doc['Answer']\n",
    "        \n",
    "        try:\n",
    "            duration = doc['Duration']\n",
    "        except:\n",
    "            duration = 0\n",
    "        \n",
    "        duration_list.append(duration)\n",
    "        answer_list.append(answer)\n",
    "        conf.append(doc['Confidence'])\n",
    "        \n",
    "    avg_duration.append(sum(duration_list)/len(duration_list))\n",
    "    conf_list.append(conf)\n",
    "    \n",
    "    original_df[exp_name[idx]] = answer_list"
=======
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ChatGPT-3.5  ChatGPT-3.5 +FT-LLM (News)  ChatGPT-3.5 +FT-LLM(News+wiki)  \\\n",
      "0      4.500000                    4.500000                        3.750000   \n",
      "1      1.000000                    1.000000                        1.666667   \n",
      "2      3.333333                    3.333333                        3.333333   \n",
      "3      4.666667                    4.333333                        4.000000   \n",
      "4      4.666667                    3.666667                        3.666667   \n",
      "5      4.750000                    5.000000                        5.000000   \n",
      "6      5.000000                    4.666667                        4.666667   \n",
      "7      2.666667                    2.666667                        2.666667   \n",
      "8      2.666667                    3.000000                        3.333333   \n",
      "9      1.666667                    3.000000                        4.666667   \n",
      "10     4.500000                    4.500000                        4.500000   \n",
      "11     5.000000                    5.000000                        5.000000   \n",
      "12     4.333333                    4.666667                        4.333333   \n",
      "13     4.666667                    4.666667                        4.666667   \n",
      "14     3.000000                    3.666667                        3.666667   \n",
      "15     4.000000                    3.000000                        3.000000   \n",
      "16     4.666667                    4.666667                        4.666667   \n",
      "17     4.000000                    2.000000                        4.333333   \n",
      "18     4.000000                    1.000000                        4.000000   \n",
      "\n",
      "    ChatGPT-3.5 +FT-LLM(News+Confidence)  ChatGPT- 4.0  \\\n",
      "0                               3.000000      4.250000   \n",
      "1                               1.000000      1.000000   \n",
      "2                               3.000000      3.666667   \n",
      "3                               4.666667      5.000000   \n",
      "4                               3.000000      5.000000   \n",
      "5                               4.250000      5.000000   \n",
      "6                               5.000000      5.000000   \n",
      "7                               2.333333      3.000000   \n",
      "8                               2.666667      2.000000   \n",
      "9                               2.666667      1.666667   \n",
      "10                              4.500000      4.500000   \n",
      "11                              5.000000      5.000000   \n",
      "12                              4.333333      4.666667   \n",
      "13                              4.666667      4.333333   \n",
      "14                              3.666667      2.000000   \n",
      "15                              4.500000      4.000000   \n",
      "16                              4.666667      4.666667   \n",
      "17                              4.333333      4.666667   \n",
      "18                              4.000000      5.000000   \n",
      "\n",
      "    ChatGPT- 4.0 + FT-LLM(News)  \n",
      "0                      4.750000  \n",
      "1                      5.000000  \n",
      "2                      4.333333  \n",
      "3                      4.333333  \n",
      "4                      4.666667  \n",
      "5                      3.000000  \n",
      "6                      4.666667  \n",
      "7                      4.666667  \n",
      "8                      5.000000  \n",
      "9                      4.666667  \n",
      "10                     5.000000  \n",
      "11                     5.000000  \n",
      "12                     5.000000  \n",
      "13                     5.000000  \n",
      "14                     4.666667  \n",
      "15                     5.000000  \n",
      "16                     4.666667  \n",
      "17                     4.666667  \n",
      "18                     5.000000  \n"
     ]
    }
   ],
   "source": [
    "# Function to extract the numerical score from a string\n",
    "def extract_score(value):\n",
    "    try:\n",
    "        return int(str(value).strip().split(':')[-1].strip()) if pd.notnull(value) else None\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Load the data\n",
    "file_path = './정성평가_민혁.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Apply the function to extract scores and convert to numeric\n",
    "cleaned_data = data.applymap(extract_score)\n",
    "\n",
    "# Remove rows with NaN values\n",
    "cleaned_data = cleaned_data.dropna()\n",
    "\n",
    "# Group by every four rows and calculate the mean for each column\n",
    "mean_values_per_column = cleaned_data.groupby(cleaned_data.index // 4).mean()\n",
    "\n",
    "# Reset the index for clean formatting if needed\n",
    "mean_values_per_column.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(mean_values_per_column)"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 48,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "[119.76091524421192, 173.88124507372495]"
      ]
     },
     "execution_count": 14,
=======
       "ChatGPT-3.5                             3.846491\n",
       "ChatGPT-3.5 +FT-LLM (News)              3.596491\n",
       "ChatGPT-3.5 +FT-LLM(News+wiki)          3.942982\n",
       "ChatGPT-3.5 +FT-LLM(News+Confidence)    3.750000\n",
       "ChatGPT- 4.0                            3.916667\n",
       "ChatGPT- 4.0 + FT-LLM(News)             4.688596\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "avg_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def extract_number(s):\n",
    "    \"\"\" Extracts the first number from a string. \"\"\"\n",
    "    json_num = s.split('/')[-1].split('.')[0]\n",
    "    return int(json_num)\n",
    "\n",
    "short_list = []\n",
    "avg_duration = []\n",
    "conf_list = []\n",
    "\n",
    "for idx, exp in enumerate(files):\n",
    "\n",
    "    output_list = glob(os.path.join(exp,\"*.json\"))\n",
    "    output_list.sort(key=extract_number)\n",
    "    \n",
    "    answer_list = []\n",
    "    duration_list = []\n",
    "    conf = []\n",
    "    \n",
    "    for x in output_list:\n",
    "        if len(output_list) != 61:\n",
    "            answer_list= ['']*61\n",
    "            break\n",
    "        \n",
    "        short_list.append(idx)\n",
    "        \n",
    "        with open(x, \"r\", encoding = \"utf-8-sig\") as f:\n",
    "            doc = json.load(f)\n",
    "\n",
    "        answer = doc['Answer']\n",
    "        try:\n",
    "            duration = doc['Duration']\n",
    "        except:\n",
    "            duration = 0\n",
    "        \n",
    "        duration_list.append(duration)\n",
    "        answer_list.append(answer)\n",
    "        conf.append(doc['Confidence'])\n",
    "        \n",
    "    avg_duration.append(sum(duration_list)/len(duration_list))\n",
    "    conf_list.append(conf)\n",
    "    \n",
    "    original_df[exp_name[idx]] = answer_list"
=======
    "mean_values_per_column.mean(axis=0)"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 53,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>BM25_news_3.5_No_refined</th>\n",
       "      <th>BM25_news_4_No_refined</th>\n",
=======
       "      <th>ChatGPT-3.5</th>\n",
       "      <th>ChatGPT-3.5 +FT-LLM (News)</th>\n",
       "      <th>ChatGPT-3.5 +FT-LLM(News+wiki)</th>\n",
       "      <th>ChatGPT-3.5 +FT-LLM(News+Confidence)</th>\n",
       "      <th>ChatGPT- 4.0</th>\n",
       "      <th>ChatGPT- 4.0 + FT-LLM(News)</th>\n",
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>축구는 총 몇분간 진행되나요?</td>\n",
       "      <td>90분</td>\n",
       "      <td>축구는 총 90분간 진행됩니다. 이는 전후반 각각 45분씩으로 구성되어 있습니다. ...</td>\n",
       "      <td>축구 경기는 기본적으로 전후반 45분씩 총 90분 동안 진행됩니다. 하지만 실제 경...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오프사이드 규칙은 무엇인가요?</td>\n",
       "      <td>오프사이드(offside, 문화어: 공격을 어김)란 축구에서 나오는 공격자 반칙 중...</td>\n",
       "      <td>오프사이드 규칙은 축구에서 공격수가 상대편 수비선보다 더 앞에 위치하여 패스를 받을...</td>\n",
       "      <td>오프사이드 규칙은 국제축구연맹(FIFA)에 의해 관리되며, 현재 규정에 따르면 상대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FIFA가 주관한 최초의 국제 축구 경기는 언제 개최되었나요?</td>\n",
       "      <td>1906년</td>\n",
       "      <td>FIFA가 주관한 최초의 국제 축구 경기는 언제 개최되었나요?\\n\\n주어진 전략에 ...</td>\n",
       "      <td>제가 가진 정보로는 FIFA가 주관한 최초의 국제 축구 경기가 언제 개최되었는지에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>축구 포지션은 어떻게 구성되나요?</td>\n",
       "      <td>축구의 포지션(Association football positions)은 각 팀 1...</td>\n",
       "      <td>축구 포지션은 팀의 전략과 감독의 결정에 따라 다양하게 구성됩니다. 일반적으로 공격...</td>\n",
       "      <td>축구 포지션은 크게 공격수, 미드필더, 수비수, 골키퍼로 나뉩니다. 각 포지션은 또...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UEFA 챔피언스 리그는 어떤 대회인가요?</td>\n",
       "      <td>UEFA 챔피언스리그(UEFA Champions League)는 유럽 최상위 축구 ...</td>\n",
       "      <td>UEFA 챔피언스 리그는 유럽 축구 연맹(UEFA)에서 주최하는 클럽 간 최고의 축...</td>\n",
       "      <td>UEFA 챔피언스 리그는 유럽 축구 연맹(UEFA)이 주관하는 클럽 팀 간의 축구 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>중원 싸움과 관련해 '4-4-2' 전술과 '4-2-3-1' 전술의 차이점에 대해 설...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'4-4-2' 전술과 '4-2-3-1' 전술의 차이점은 다음과 같습니다.\\n\\n'4...</td>\n",
       "      <td>'4-4-2' 전략과 '4-2-3-1' 전략은 둘 다 축구 전술의 한 종류로, 각각...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2022-2023 시즌에 UEFA 챔피언스 리그에서 4강 이상에 진출한 팀 중, 기...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-2023 시즌 UEFA 챔피언스 리그에서 4강 이상에 진출한 팀 중, 기술...</td>\n",
       "      <td>제공된 전략에 따르면, 2022-2023 시즌 UEFA 챔피언스 리그에서 4강 이상...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>축구를 통해 어떤 사회적 메시지가 전달되기도 하나요?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>축구를 통해는 다양한 사회적 메시지가 전달될 수 있습니다. 예를 들어, 첼시 축구 ...</td>\n",
       "      <td>축구를 통해 다양한 사회적 메시지가 전달되고 있습니다. 그 중 하나로 '흑인 목숨도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>축구 경기 중에 어떤 통계가 중요하게 사용되나요? 그리고 그 통계의 의미나 중요성은...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>축구 경기 중에는 다양한 종류의 통계가 중요하게 사용됩니다. 예를 들어, 선수들의 ...</td>\n",
       "      <td>축구 경기에서는 여러 가지 통계가 중요하게 사용됩니다. 가장 대표적인 통계로는 골,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>FIFA 월드컵 예선 기간 동안, 어느 지역(예: 남미, 유럽, 아시아)의 예선 경...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>남미 지역의 예선 경기가 가장 치열한 경쟁을 가졌습니다. 주요 팀들 중에서는 브라질...</td>\n",
       "      <td>FIFA 월드컵 예선 기간 동안, 남미 지역의 예선 경기가 가장 치열한 경쟁을 보여...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  \\\n",
       "0                                    축구는 총 몇분간 진행되나요?   \n",
       "1                                    오프사이드 규칙은 무엇인가요?   \n",
       "2                  FIFA가 주관한 최초의 국제 축구 경기는 언제 개최되었나요?   \n",
       "3                                  축구 포지션은 어떻게 구성되나요?   \n",
       "4                            UEFA 챔피언스 리그는 어떤 대회인가요?    \n",
       "..                                                ...   \n",
       "56  중원 싸움과 관련해 '4-4-2' 전술과 '4-2-3-1' 전술의 차이점에 대해 설...   \n",
       "57  2022-2023 시즌에 UEFA 챔피언스 리그에서 4강 이상에 진출한 팀 중, 기...   \n",
       "58                      축구를 통해 어떤 사회적 메시지가 전달되기도 하나요?   \n",
       "59  축구 경기 중에 어떤 통계가 중요하게 사용되나요? 그리고 그 통계의 의미나 중요성은...   \n",
       "60  FIFA 월드컵 예선 기간 동안, 어느 지역(예: 남미, 유럽, 아시아)의 예선 경...   \n",
       "\n",
       "                                               Answer  \\\n",
       "0                                                 90분   \n",
       "1   오프사이드(offside, 문화어: 공격을 어김)란 축구에서 나오는 공격자 반칙 중...   \n",
       "2                                               1906년   \n",
       "3   축구의 포지션(Association football positions)은 각 팀 1...   \n",
       "4   UEFA 챔피언스리그(UEFA Champions League)는 유럽 최상위 축구 ...   \n",
       "..                                                ...   \n",
       "56                                                NaN   \n",
       "57                                                NaN   \n",
       "58                                                NaN   \n",
       "59                                                NaN   \n",
       "60                                                NaN   \n",
       "\n",
       "                             BM25_news_3.5_No_refined  \\\n",
       "0   축구는 총 90분간 진행됩니다. 이는 전후반 각각 45분씩으로 구성되어 있습니다. ...   \n",
       "1   오프사이드 규칙은 축구에서 공격수가 상대편 수비선보다 더 앞에 위치하여 패스를 받을...   \n",
       "2   FIFA가 주관한 최초의 국제 축구 경기는 언제 개최되었나요?\\n\\n주어진 전략에 ...   \n",
       "3   축구 포지션은 팀의 전략과 감독의 결정에 따라 다양하게 구성됩니다. 일반적으로 공격...   \n",
       "4   UEFA 챔피언스 리그는 유럽 축구 연맹(UEFA)에서 주최하는 클럽 간 최고의 축...   \n",
       "..                                                ...   \n",
       "56  '4-4-2' 전술과 '4-2-3-1' 전술의 차이점은 다음과 같습니다.\\n\\n'4...   \n",
       "57  2022-2023 시즌 UEFA 챔피언스 리그에서 4강 이상에 진출한 팀 중, 기술...   \n",
       "58  축구를 통해는 다양한 사회적 메시지가 전달될 수 있습니다. 예를 들어, 첼시 축구 ...   \n",
       "59  축구 경기 중에는 다양한 종류의 통계가 중요하게 사용됩니다. 예를 들어, 선수들의 ...   \n",
       "60  남미 지역의 예선 경기가 가장 치열한 경쟁을 가졌습니다. 주요 팀들 중에서는 브라질...   \n",
       "\n",
       "                               BM25_news_4_No_refined  \n",
       "0   축구 경기는 기본적으로 전후반 45분씩 총 90분 동안 진행됩니다. 하지만 실제 경...  \n",
       "1   오프사이드 규칙은 국제축구연맹(FIFA)에 의해 관리되며, 현재 규정에 따르면 상대...  \n",
       "2   제가 가진 정보로는 FIFA가 주관한 최초의 국제 축구 경기가 언제 개최되었는지에 ...  \n",
       "3   축구 포지션은 크게 공격수, 미드필더, 수비수, 골키퍼로 나뉩니다. 각 포지션은 또...  \n",
       "4   UEFA 챔피언스 리그는 유럽 축구 연맹(UEFA)이 주관하는 클럽 팀 간의 축구 ...  \n",
       "..                                                ...  \n",
       "56  '4-4-2' 전략과 '4-2-3-1' 전략은 둘 다 축구 전술의 한 종류로, 각각...  \n",
       "57  제공된 전략에 따르면, 2022-2023 시즌 UEFA 챔피언스 리그에서 4강 이상...  \n",
       "58  축구를 통해 다양한 사회적 메시지가 전달되고 있습니다. 그 중 하나로 '흑인 목숨도...  \n",
       "59  축구 경기에서는 여러 가지 통계가 중요하게 사용됩니다. 가장 대표적인 통계로는 골,...  \n",
       "60  FIFA 월드컵 예선 기간 동안, 남미 지역의 예선 경기가 가장 치열한 경쟁을 보여...  \n",
       "\n",
       "[61 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
=======
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ChatGPT-3.5  ChatGPT-3.5 +FT-LLM (News)  ChatGPT-3.5 +FT-LLM(News+wiki)  \\\n",
       "0      4.500000                    4.500000                        3.750000   \n",
       "1      1.000000                    1.000000                        1.666667   \n",
       "2      3.333333                    3.333333                        3.333333   \n",
       "3      4.666667                    4.333333                        4.000000   \n",
       "4      4.666667                    3.666667                        3.666667   \n",
       "5      4.750000                    5.000000                        5.000000   \n",
       "6      5.000000                    4.666667                        4.666667   \n",
       "7      2.666667                    2.666667                        2.666667   \n",
       "8      2.666667                    3.000000                        3.333333   \n",
       "9      1.666667                    3.000000                        4.666667   \n",
       "10     4.500000                    4.500000                        4.500000   \n",
       "11     5.000000                    5.000000                        5.000000   \n",
       "12     4.333333                    4.666667                        4.333333   \n",
       "13     4.666667                    4.666667                        4.666667   \n",
       "14     3.000000                    3.666667                        3.666667   \n",
       "15     4.000000                    3.000000                        3.000000   \n",
       "16     4.666667                    4.666667                        4.666667   \n",
       "17     4.000000                    2.000000                        4.333333   \n",
       "18     4.000000                    1.000000                        4.000000   \n",
       "\n",
       "    ChatGPT-3.5 +FT-LLM(News+Confidence)  ChatGPT- 4.0  \\\n",
       "0                               3.000000      4.250000   \n",
       "1                               1.000000      1.000000   \n",
       "2                               3.000000      3.666667   \n",
       "3                               4.666667      5.000000   \n",
       "4                               3.000000      5.000000   \n",
       "5                               4.250000      5.000000   \n",
       "6                               5.000000      5.000000   \n",
       "7                               2.333333      3.000000   \n",
       "8                               2.666667      2.000000   \n",
       "9                               2.666667      1.666667   \n",
       "10                              4.500000      4.500000   \n",
       "11                              5.000000      5.000000   \n",
       "12                              4.333333      4.666667   \n",
       "13                              4.666667      4.333333   \n",
       "14                              3.666667      2.000000   \n",
       "15                              4.500000      4.000000   \n",
       "16                              4.666667      4.666667   \n",
       "17                              4.333333      4.666667   \n",
       "18                              4.000000      5.000000   \n",
       "\n",
       "    ChatGPT- 4.0 + FT-LLM(News)  \n",
       "0                      4.750000  \n",
       "1                      5.000000  \n",
       "2                      4.333333  \n",
       "3                      4.333333  \n",
       "4                      4.666667  \n",
       "5                      3.000000  \n",
       "6                      4.666667  \n",
       "7                      4.666667  \n",
       "8                      5.000000  \n",
       "9                      4.666667  \n",
       "10                     5.000000  \n",
       "11                     5.000000  \n",
       "12                     5.000000  \n",
       "13                     5.000000  \n",
       "14                     4.666667  \n",
       "15                     5.000000  \n",
       "16                     4.666667  \n",
       "17                     4.666667  \n",
       "18                     5.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.to_csv('/Project/src/outputs/revision/answer_no_refined.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_f1(gold_answers, candidate_answer):\n",
    "    \"\"\"\n",
    "    Compute the F1 score for a candidate answer with respect to a set of gold answers.\n",
    "    \n",
    "    Parameters:\n",
    "    - gold_answers (list of str): A list of gold (correct) answers.\n",
    "    - candidate_answer (str): The candidate answer to evaluate.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The maximum F1 score for the candidate answer with respect to the gold answers.\n",
    "    \"\"\"\n",
    "    max_f1 = 0.0\n",
    "    \n",
    "    # Tokenize the candidate answer\n",
    "    candidate_tokens = set(candidate_answer.split())\n",
    "    \n",
    "    for gold_answer in gold_answers:\n",
    "        # Tokenize the gold answer\n",
    "        gold_tokens = set(gold_answer.split())\n",
    "        \n",
    "        # Calculate the number of overlapping tokens\n",
    "        common_tokens = candidate_tokens.intersection(gold_tokens)\n",
    "        \n",
    "        # Compute precision and recall\n",
    "        precision = len(common_tokens) / len(candidate_tokens)\n",
    "        recall = len(common_tokens) / len(gold_tokens)\n",
    "        \n",
    "        # Compute F1 score\n",
    "        if precision + recall == 0:\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        # Update the maximum F1 score\n",
    "        max_f1 = max(max_f1, f1)\n",
    "    \n",
    "    return max_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = original_df.loc[:45,'Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_f1_list = []\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    response = original_df[original_df.columns[i+2]]\n",
    "\n",
    "    f1_score = 0.0\n",
    "    for j in range(len(label)):\n",
    "        try:\n",
    "            gold_answers = [label[j]]\n",
    "            candidate_answer = response[j]\n",
    "            f1 = compute_f1(gold_answers, candidate_answer)\n",
    "        except:\n",
    "            f1 = 0.0\n",
    "            \n",
    "        f1_score+=f1\n",
    "        \n",
    "    avg_f1 = f1_score/len(label)\n",
    "    \n",
    "    avg_f1_list.append(avg_f1)"
=======
    "mean_values_per_column"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 64,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "[0.028768825901527195, 0.042956454700658356]"
      ]
     },
     "execution_count": 16,
=======
       "5"
      ]
     },
     "execution_count": 64,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "avg_f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = ['Embedding_news_Conf_3.5', 'Embedding_news_No_Conf_3.5', 'Embedding_news_wiki_Conf_3.5',\n",
    "            'BM25_news_Conf_4', 'BM25_news_wiki_Conf_4',\n",
    "            'Embedding_news_Conf_4', 'Embedding_news_Conf_3_k_2', 'Embedding_news_Conf_3_k_1',\n",
    "            'Embedding_news_No_Conf_4', 'Embedding_news_No_Conf_4_No_refine', 'Embedding_news_wiki_Conf_4',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acc_GPT Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_human_prompt = '''\n",
    "\n",
    "{{#user~}}\n",
    "\n",
    "Question: {{question}}\n",
    "\n",
    "Answer: {{answer}}\n",
    "\n",
    "Candidate: {{candidate}}\n",
    "\n",
    "Is candidate correct? Answer 0 for No and 1 for Yes\n",
    "\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "\n",
    "{{gen \"answer\" max_tokens=1 temperature=0.0 n=1}}\n",
    "\n",
    "{{~/assistant}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = original_df.loc[:45,'Question']\n",
    "answer = original_df.loc[:45,'Answer']\n",
    "candidate = original_df.loc[:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate.to_csv('/Project/src/outputs/revision/unrefied_candidate.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.loc[45:].to_csv('/Project/src/outputs/revision/unrefied_candidate_subjective.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "import guidance \n",
    "import numpy as np\n",
    "\n",
    "all_model_list = []\n",
    "api_key = ''\n",
    "\n",
    "for i in tqdm(range(2)):\n",
    "    per_model_list = []\n",
    "\n",
    "    for j in tqdm(range(len(questions))):\n",
    "\n",
    "        llm = guidance.llms.OpenAI(\"gpt-4\", caching=True,\n",
    "                                    api_key = api_key\n",
    "                                    ) \n",
    "        guidance.llm = llm \n",
    "\n",
    "        guidance.llm.cache.clear()\n",
    "\n",
    "        structure_program = guidance(acc_human_prompt, \n",
    "                                    question = questions[j], \n",
    "                                    answer = answer[j],\n",
    "                                    candidate = candidate[candidate.columns[i+2]][j],\n",
    "                                    silent = True\n",
    "                                    )\n",
    "\n",
    "        res = structure_program()\n",
    "\n",
    "        binary_answer = int(res['answer'])\n",
    "        \n",
    "        per_model_list.append(binary_answer)\n",
    "    \n",
    "    all_model_list.append(per_model_list)\n",
    "    binary_list = np.array(all_model_list)\n",
    "    metric_df = pd.DataFrame(binary_list.T, columns = original_df.columns[3:4+i])\n",
    "    metric_df.to_csv('/Project/src/outputs/revision/objective.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = pd.DataFrame(binary_list.T, columns = original_df.columns[2:4])\n",
    "metric_df.to_csv('/Project/src/outputs/revision/objective_unrefined.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_obj_df = pd.read_csv('/Project/src/outputs/revision/objective_unrefined.csv')"
=======
    "sum(mean_values_per_column['ChatGPT- 4.0']<mean_values_per_column['ChatGPT-3.5 +FT-LLM (News)'])"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 50,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "BM25_news_3.5_No_refined    0.391304\n",
       "BM25_news_4_No_refined      0.608696\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
=======
       "4"
      ]
     },
     "execution_count": 50,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
<<<<<<< HEAD
   "source": [
    "eval_obj_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('/Project/src/ChatGPT_3.5_주관적_aspect.csv')"
=======
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./객관적.csv')"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_FT_4 = pd.read_csv('/Project/src/ChatGPT_4.0_FT_주관적_aspect.csv')"
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df['Original Question']"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_FT_4 = pd.read_csv('/Project/src/outputs/revision/FT-LLM_unrefined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to extract the numerical score from a string\n",
    "def extract_score(value):\n",
    "    try:\n",
    "        if pd.notnull(value):\n",
    "    \n",
    "            score_list = list(map(lambda x: int(x),re.findall(r'\\d+', value.strip())))\n",
    "            \n",
    "            return sum(score_list)/len(score_list)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Load the data\n",
    "file_path = '/Project/src/outputs/revision/FT-LLM_unrefined.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data.drop(columns=['Unnamed: 0','Original Question', 'Human Reference','Unnamed: 5'], inplace=True)\n",
    "\n",
    "# Apply the function to extract scores and convert to numeric\n",
    "cleaned_data = data.applymap(extract_score)\n",
    "\n",
    "# Remove rows with NaN values\n",
    "cleaned_data = cleaned_data.dropna()"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df['Golden Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BM25_news_3.5_No_refined</th>\n",
       "      <th>BM25_news_4_No_refined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nFactuality: 2\\nCoherence: 2\\nReasoning: 2\\nI...</td>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 4\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 4\\nI...</td>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 4\\nReasoning: 4\\nI...</td>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 4\\nReasoning: 4\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nFactuality: 3\\nCoherence: 2\\nReasoning: 3\\nI...</td>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 4\\nReasoning: 5\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nFactuality: 4\\nCoherence: 3\\nReasoning: 3\\nI...</td>\n",
       "      <td>\\nFactuality: 4\\nCoherence: 4\\nReasoning: 4\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 4\\nReasoning: 4\\nI...</td>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nFactuality: 1\\nCoherence: 2\\nReasoning: 2\\nI...</td>\n",
       "      <td>\\nFactuality: 4\\nCoherence: 3\\nReasoning: 3\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nFactuality: 1\\nCoherence: 2\\nReasoning: 2\\nI...</td>\n",
       "      <td>\\nFactuality: 1\\nCoherence: 2\\nReasoning: 2\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...</td>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...</td>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...</td>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\nFactuality: 1\\nCoherence: 2\\nReasoning: 2\\nI...</td>\n",
       "      <td>\\nFactuality: 1\\nCoherence: 2\\nReasoning: 2\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...</td>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\nFactuality: 4\\nCoherence: 3\\nReasoning: 3\\nI...</td>\n",
       "      <td>\\nFactuality: 4\\nCoherence: 4\\nReasoning: 4\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 4\\nI...</td>\n",
       "      <td>\\nFactuality: 5\\nCoherence: 5\\nReasoning: 4\\nI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             BM25_news_3.5_No_refined  \\\n",
       "0   \\nFactuality: 2\\nCoherence: 2\\nReasoning: 2\\nI...   \n",
       "1   \\nFactuality: 5\\nCoherence: 5\\nReasoning: 4\\nI...   \n",
       "2   \\nFactuality: 5\\nCoherence: 4\\nReasoning: 4\\nI...   \n",
       "3   \\nFactuality: 3\\nCoherence: 2\\nReasoning: 3\\nI...   \n",
       "4   \\nFactuality: 4\\nCoherence: 3\\nReasoning: 3\\nI...   \n",
       "5   \\nFactuality: 5\\nCoherence: 4\\nReasoning: 4\\nI...   \n",
       "6   \\nFactuality: 1\\nCoherence: 2\\nReasoning: 2\\nI...   \n",
       "7   \\nFactuality: 1\\nCoherence: 2\\nReasoning: 2\\nI...   \n",
       "8   \\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...   \n",
       "9   \\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...   \n",
       "10  \\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...   \n",
       "11  \\nFactuality: 1\\nCoherence: 2\\nReasoning: 2\\nI...   \n",
       "12  \\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...   \n",
       "13  \\nFactuality: 4\\nCoherence: 3\\nReasoning: 3\\nI...   \n",
       "14  \\nFactuality: 5\\nCoherence: 5\\nReasoning: 4\\nI...   \n",
       "\n",
       "                               BM25_news_4_No_refined  \n",
       "0   \\nFactuality: 5\\nCoherence: 5\\nReasoning: 4\\nI...  \n",
       "1   \\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...  \n",
       "2   \\nFactuality: 5\\nCoherence: 4\\nReasoning: 4\\nI...  \n",
       "3   \\nFactuality: 5\\nCoherence: 4\\nReasoning: 5\\nI...  \n",
       "4   \\nFactuality: 4\\nCoherence: 4\\nReasoning: 4\\nI...  \n",
       "5   \\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...  \n",
       "6   \\nFactuality: 4\\nCoherence: 3\\nReasoning: 3\\nI...  \n",
       "7   \\nFactuality: 1\\nCoherence: 2\\nReasoning: 2\\nI...  \n",
       "8   \\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...  \n",
       "9   \\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...  \n",
       "10  \\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...  \n",
       "11  \\nFactuality: 1\\nCoherence: 2\\nReasoning: 2\\nI...  \n",
       "12  \\nFactuality: 5\\nCoherence: 5\\nReasoning: 5\\nI...  \n",
       "13  \\nFactuality: 4\\nCoherence: 4\\nReasoning: 4\\nI...  \n",
       "14  \\nFactuality: 5\\nCoherence: 5\\nReasoning: 4\\nI...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
=======
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_f1(gold_answers, candidate_answer):\n",
    "    \"\"\"\n",
    "    Compute the F1 score for a candidate answer with respect to a set of gold answers.\n",
    "    \n",
    "    Parameters:\n",
    "    - gold_answers (list of str): A list of gold (correct) answers.\n",
    "    - candidate_answer (str): The candidate answer to evaluate.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The maximum F1 score for the candidate answer with respect to the gold answers.\n",
    "    \"\"\"\n",
    "    max_f1 = 0.0\n",
    "    \n",
    "    # Tokenize the candidate answer\n",
    "    candidate_tokens = set(candidate_answer.split())\n",
    "    \n",
    "    for gold_answer in gold_answers:\n",
    "        # Tokenize the gold answer\n",
    "        gold_tokens = set(gold_answer.split())\n",
    "        \n",
    "        # Calculate the number of overlapping tokens\n",
    "        common_tokens = candidate_tokens.intersection(gold_tokens)\n",
    "        \n",
    "        # Compute precision and recall\n",
    "        precision = len(common_tokens) / len(candidate_tokens)\n",
    "        recall = len(common_tokens) / len(gold_tokens)\n",
    "        \n",
    "        # Compute F1 score\n",
    "        if precision + recall == 0:\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        # Update the maximum F1 score\n",
    "        max_f1 = max(max_f1, f1)\n",
    "    \n",
    "    return max_f1\n"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BM25_news_3.5_No_refined</th>\n",
       "      <th>BM25_news_4_No_refined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.75</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.25</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.75</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.75</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.75</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.75</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.25</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BM25_news_3.5_No_refined  BM25_news_4_No_refined\n",
       "0                       2.00                    4.50\n",
       "1                       4.75                    5.00\n",
       "2                       4.25                    4.25\n",
       "3                       2.75                    4.50\n",
       "4                       3.25                    3.75\n",
       "5                       4.00                    5.00\n",
       "6                       1.75                    3.25\n",
       "7                       1.75                    1.75\n",
       "8                       5.00                    5.00\n",
       "9                       5.00                    4.75\n",
       "10                      5.00                    5.00\n",
       "11                      1.75                    1.75\n",
       "12                      5.00                    5.00\n",
       "13                      3.25                    4.00\n",
       "14                      4.50                    4.50"
      ]
     },
     "execution_count": 57,
=======
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_f1_list = []\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    response = df[df.columns[i+3]]\n",
    "\n",
    "    f1_score = 0.0\n",
    "    for j in range(len(label)):\n",
    "        try:\n",
    "            gold_answers = [label[j]]\n",
    "            candidate_answer = response[j]\n",
    "            f1 = compute_f1(gold_answers, candidate_answer)\n",
    "        except:\n",
    "            f1 = 0.0\n",
    "            \n",
    "        f1_score+=f1\n",
    "        \n",
    "    avg_f1 = f1_score/len(label)\n",
    "    \n",
    "    avg_f1_list.append(avg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ChatGPT-3.5', 'ChatGPT-3.5 +FT-LLM (News)',\n",
       "       'ChatGPT-3.5 +FT-LLM\\n(News+wiki)',\n",
       "       'ChatGPT-3.5 +FT-LLM\\n(News+Confidence)', 'ChatGPT- 4.0',\n",
       "       'ChatGPT- 4.0 + FT-LLM\\n(News)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "cleaned_data"
=======
    "df.columns[3:]"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BM25_news_3.5_No_refined  BM25_news_4_No_refined\n",
      "0                    3.4375                  4.5625\n",
      "1                    2.6875                  3.4375\n",
      "2                    4.1875                  4.1250\n",
      "3                    4.2500                  4.5000\n"
=======
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027924029274846187,\n",
       " 0.03899884908201792,\n",
       " 0.0327412471872984,\n",
       " 0.0540846637651834,\n",
       " 0.03516970900138079,\n",
       " 0.06696117699902547]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_f1_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acc_Human Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_human_prompt = '''\n",
    "\n",
    "{{#user~}}\n",
    "\n",
    "Question: {{question}}\n",
    "\n",
    "Answer: {{answer}}\n",
    "\n",
    "Candidate: {{candidate}}\n",
    "\n",
    "Is candidate correct? Answer 0 for No and 1 for Yes\n",
    "\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "\n",
    "{{gen \"answer\" max_tokens=1 temperature=0.0 n=1}}\n",
    "\n",
    "{{~/assistant}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [04:25<00:00, 44.29s/it]\n"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Group by every four rows and calculate the mean for each column\n",
    "mean_values_per_column = cleaned_data.groupby(cleaned_data.index // 4).mean()\n",
    "\n",
    "# Reset the index for clean formatting if needed\n",
    "mean_values_per_column.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(mean_values_per_column)"
=======
    "from tqdm import tqdm \n",
    "import guidance \n",
    "\n",
    "all_model_list = []\n",
    "\n",
    "for i in tqdm(range(6)):\n",
    "    per_model_list = []\n",
    "\n",
    "    for j in range(len(questions)):\n",
    "\n",
    "        llm = guidance.llms.OpenAI(\"gpt-4\", caching=True,\n",
    "                                    api_key = \"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\",\n",
    "                                    ) \n",
    "        guidance.llm = llm \n",
    "\n",
    "        guidance.llm.cache.clear()\n",
    "\n",
    "        structure_program = guidance(acc_human_prompt, \n",
    "                                    question = questions[j], \n",
    "                                    answer = label[j],\n",
    "                                    candidate = df[df.columns[i+3]][j],\n",
    "                                    silent = True\n",
    "                                    )\n",
    "\n",
    "        res = structure_program()\n",
    "\n",
    "        binary_answer = int(res['answer'])\n",
    "        \n",
    "        per_model_list.append(binary_answer)\n",
    "    \n",
    "    all_model_list.append(per_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "binary_list = np.array(all_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = pd.DataFrame(binary_list.T, columns = df.columns[3:])"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 59,
=======
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.to_csv('./ACC_GPT_객관적.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "BM25_news_3.5_No_refined    3.640625\n",
       "BM25_news_4_No_refined      4.156250\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
=======
       "ChatGPT-3.5                               0.500000\n",
       "ChatGPT-3.5 +FT-LLM (News)                0.391304\n",
       "ChatGPT-3.5 +FT-LLM\\n(News+wiki)          0.391304\n",
       "ChatGPT-3.5 +FT-LLM\\n(News+Confidence)    0.565217\n",
       "ChatGPT- 4.0                              0.543478\n",
       "ChatGPT- 4.0 + FT-LLM\\n(News)             0.695652\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "mean_values_per_column.apply(lambda x: sum(x)/len(x), axis = 0)"
=======
    "metric_df.apply(lambda x: sum(x)/len(x), axis = 0)"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval_GPT"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./주관적.csv')"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 61,
=======
   "execution_count": 7,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "'1.7.4'"
      ]
     },
     "execution_count": 61,
=======
       "Index(['ChatGPT-3.5', 'ChatGPT-3.5 +FT-LLM (News)',\n",
       "       'ChatGPT-3.5 +FT-LLM\\n(News+wiki)',\n",
       "       'ChatGPT-3.5 +FT-LLM\\n(News+Confidence)', 'ChatGPT- 4.0',\n",
       "       'ChatGPT- 4.0 + FT-LLM\\n(News)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "faiss.__version__"
=======
    "df.columns[3:]"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "subjective = pd.read_csv(('/Project/src/주관적.csv'))\n",
    "questions = subjective['Original Question']\n",
    "answer = subjective['Human Reference']\n",
    "candidate = original_df.loc[46:]"
=======
    "questions = df['Original Question']\n",
    "reference = df['Human Reference']\n",
    "answers = df[df.columns[3:]]"
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gpt_prompt = '''\n",
    "{{#user~}}\n",
    "\n",
    "You will be given series of sentences written as a response for football related question.\n",
    " \n",
    "Your task is to rate the summary on one metric.\n",
    "\n",
    "Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\n",
    "\n",
    "Evaluation Criteria:\n",
    "\n",
    "{{aspect}} (1-5) {{aspect_definition}}}\n",
    "\n",
    "Evaluation Steps:\n",
    "\n",
    "1. Read the response carefully and identify the main topic and key points.\n",
    "2. Read the response and compare it to the reference. Check if the response maintains similar tone and context compared to the reference.\n",
    "3. Assign a score for {{aspect}} on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\n",
    "\n",
    "\n",
    "Question\n",
    "{{question}}\n",
    "\n",
    "Reference\n",
    "{{reference}}\n",
    "\n",
    "Answer\n",
    "{{answer}}\n",
    "\n",
    "Score for {{aspect}} (1-5): \n",
    "\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "\n",
    "{{gen \"answer\" max_tokens=1 temperature=0.0 n=1}}\n",
    "\n",
    "{{~/assistant}}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_dict = {\n",
    "    'Factuality' : 'Is the information provided in the response factually grounded?',\n",
    "    'Relevance' : 'How consistent is the content in your answer with the content in the Golden Label?',\n",
    "    'Reasoning' : 'How logical and natural is the content of the answer compared to the Human reference?',\n",
    "    'Interestingness' : 'Does the answer provide interesting or innovative insights or information at a level equivalent to the Human reference?'\n",
    "}\n",
    "\n",
    "aspect_list = ['Factuality', 'Relevance', 'Reasoning', 'Interestingness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-7c62fcd8-7dbd-46a7-8f0a-15254ae577ed\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-7c62fcd8-7dbd-46a7-8f0a-15254ae577ed\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You will be given series of sentences written as a response for football related question.\n",
       " \n",
       "Your task is to rate the summary on one metric.\n",
       "\n",
       "Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\n",
       "\n",
       "Evaluation Criteria:\n",
       "\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{aspect}}'>Interestingness</span> (1-5) <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{aspect_definition}}'>Does the answer provide interesting or innovative insights or information at a level equivalent to the Human reference?</span>}\n",
       "\n",
       "Evaluation Steps:\n",
       "\n",
       "1. Read the response carefully and identify the main topic and key points.\n",
       "2. Read the response and compare it to the reference. Check if the response maintains similar tone and context compared to the reference.\n",
       "3. Assign a score for <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{aspect}}'>Interestingness</span> on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\n",
       "\n",
       "\n",
       "Question\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{question}}'>FIFA 월드컵 예선 기간 동안, 어느 지역(예: 남미, 유럽, 아시아)의 예선 경기가 가장 치열한 경쟁을 가지나요? 그 지역의 주요 팀들 중 누가 가장 큰 경쟁을 겪었나요?</span>\n",
       "\n",
       "Reference\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{reference}}'> 제일 치열한 경쟁이란 팀들간의 실력 편차가 별로 크지 않아 누가 예선을 통과할지 모르는 상황이라고 생각합니다. 그러므로 매번 월드컵에서 본선에 올라오는 팀이 가장 많이 바뀌는 아프리카를 뽑고 싶습니다. 국가 수가 많은 유럽이나 아시아도 본선에 올라오는 팀들은 자주 올라오는 반면, 아프리카는 얼핏 생각해도 빈도가 너무 자주 바뀝니다. \n",
       " 다들 실력이 비슷하여 누가 가장 큰 경쟁을 겪었을까 고르기 쉽지 않지만, 아프리카에서 가장 많이 본선을 진출한 카메룬이 항상 큰 경쟁을 마치고 본선에 진출했으니 제일 치열했다고 생각합니다.. </span>\n",
       "\n",
       "Answer\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{answer}}'>&quot;FIFA 월드컵 예선 기간 동안, 남미 지역의 예선 경기가 가장 치열한 경쟁을 보여주었습니다. 특히 에콰도르는 브라질, 아르헨티나, 우루과이와 같은 강팀들과 치열한 경쟁을 벌였습니다. 에콰도르는 브라질, 아르헨티나에 이어 4위로 지역 예선을 마감했으며, 우루과이와의 승점 차는 단 2점이었습니다. 또한 에콰도르는 월드컵 남미 지역 예선 경기에서 &#x27;부정선수&#x27; 논란을 겪었는데, 콜롬비아 출신의 바이런 카스티요를 그라운드에 내보냈다는 의혹을 받았습니다. 이러한 사항들로 보아, 에콰도르 팀이 가장 큰 경쟁을 겪었다고 볼 수 있습니다.&quot;</span>\n",
       "\n",
       "Score for <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{aspect}}'>Interestingness</span> (1-5):</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &quot;answer&quot; max_tokens=1 temperature=0.0 n=1}}'>3</span></div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"7c62fcd8-7dbd-46a7-8f0a-15254ae577ed\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:29<00:00, 17.93s/it]\n"
     ]
    }
   ],
   "source": [
    "import guidance\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "all_model_list = []\n",
    "per_model_save_list = []\n",
<<<<<<< HEAD
    "api_key = ''\n",
=======
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
    "\n",
    "for i in range(6):\n",
    "    per_model_list = []\n",
    "    #per_model_save_list = []\n",
    "    \n",
    "    for j in tqdm(range(len(questions))):\n",
    "        \n",
    "        aspect_score = []\n",
    "\n",
    "        for aspect in aspect_list:\n",
    "\n",
    "            llm = guidance.llms.OpenAI(\"gpt-4\", caching=True,\n",
<<<<<<< HEAD
    "                                        api_key = api_key,\n",
=======
    "                                        api_key = \"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\",\n",
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
    "                                        ) \n",
    "            guidance.llm = llm \n",
    "\n",
    "            guidance.llm.cache.clear()\n",
    "\n",
    "            try:\n",
    "                structure_program = guidance(eval_gpt_prompt, \n",
    "                                            aspect = aspect,\n",
    "                                            aspect_definition = aspect_dict[aspect],\n",
    "                                            question = questions[j], \n",
    "                                            reference = reference[j],\n",
    "                                            answer = df[df.columns[i+3]][j],\n",
    "                                            silent = False\n",
    "                                            )\n",
    "\n",
    "                res = structure_program()\n",
    "\n",
    "                scaled_answer = int(res['answer'])\n",
    "            \n",
    "            except:\n",
    "                scaled_answer = 3\n",
    "                print('Error')\n",
    "                        \n",
    "            aspect_score.append(scaled_answer)\n",
    "        \n",
    "        per_model_save_list.append(aspect_score)\n",
    "        \n",
    "        final_score = sum(aspect_score)/len(aspect_score)\n",
    "        per_model_list.append(final_score)\n",
    "    \n",
    "    all_model_list.append(per_model_list)\n",
    "    \n",
    "\n",
    "model_score = pd.DataFrame(np.array(all_model_list).T)\n",
    "model_score.columns = df.columns[3:]\n",
    "model_score.to_csv(f'./주관적_total.csv', index = False)\n",
    "\n",
    "per_model_save_list = np.array(per_model_save_list).reshape(6,15,4)\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    temp_df = pd.DataFrame(per_model_save_list[i])\n",
    "    temp_df.columns = aspect_list\n",
    "    file_name = df.columns[3:][i]\n",
    "    temp_df.to_csv(f'./{file_name}_주관적_aspect.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('/Project/src/ChatGPT_3.5_주관적_aspect.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_FT_4 = pd.read_csv('/Project/src/ChatGPT_4.0_FT_주관적_aspect.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ChatGPT-3.5  ChatGPT-3.5 +FT-LLM (News)  ChatGPT-3.5 +FT-LLM(News+wiki)  \\\n",
      "0      4.500000                    4.500000                        3.750000   \n",
      "1      1.000000                    1.000000                        1.666667   \n",
      "2      3.333333                    3.333333                        3.333333   \n",
      "3      4.666667                    4.333333                        4.000000   \n",
      "4      4.666667                    3.666667                        3.666667   \n",
      "5      4.750000                    5.000000                        5.000000   \n",
      "6      5.000000                    4.666667                        4.666667   \n",
      "7      2.666667                    2.666667                        2.666667   \n",
      "8      2.666667                    3.000000                        3.333333   \n",
      "9      1.666667                    3.000000                        4.666667   \n",
      "10     4.500000                    4.500000                        4.500000   \n",
      "11     5.000000                    5.000000                        5.000000   \n",
      "12     4.333333                    4.666667                        4.333333   \n",
      "13     4.666667                    4.666667                        4.666667   \n",
      "14     3.000000                    3.666667                        3.666667   \n",
      "15     4.000000                    3.000000                        3.000000   \n",
      "16     4.666667                    4.666667                        4.666667   \n",
      "17     4.000000                    2.000000                        4.333333   \n",
      "18     4.000000                    1.000000                        4.000000   \n",
      "\n",
      "    ChatGPT-3.5 +FT-LLM(News+Confidence)  ChatGPT- 4.0  \\\n",
      "0                               3.000000      4.250000   \n",
      "1                               1.000000      1.000000   \n",
      "2                               3.000000      3.666667   \n",
      "3                               4.666667      5.000000   \n",
      "4                               3.000000      5.000000   \n",
      "5                               4.250000      5.000000   \n",
      "6                               5.000000      5.000000   \n",
      "7                               2.333333      3.000000   \n",
      "8                               2.666667      2.000000   \n",
      "9                               2.666667      1.666667   \n",
      "10                              4.500000      4.500000   \n",
      "11                              5.000000      5.000000   \n",
      "12                              4.333333      4.666667   \n",
      "13                              4.666667      4.333333   \n",
      "14                              3.666667      2.000000   \n",
      "15                              4.500000      4.000000   \n",
      "16                              4.666667      4.666667   \n",
      "17                              4.333333      4.666667   \n",
      "18                              4.000000      5.000000   \n",
      "\n",
      "    ChatGPT- 4.0 + FT-LLM(News)  \n",
      "0                      4.750000  \n",
      "1                      5.000000  \n",
      "2                      4.333333  \n",
      "3                      4.333333  \n",
      "4                      4.666667  \n",
      "5                      3.000000  \n",
      "6                      4.666667  \n",
      "7                      4.666667  \n",
      "8                      5.000000  \n",
      "9                      4.666667  \n",
      "10                     5.000000  \n",
      "11                     5.000000  \n",
      "12                     5.000000  \n",
      "13                     5.000000  \n",
      "14                     4.666667  \n",
      "15                     5.000000  \n",
      "16                     4.666667  \n",
      "17                     4.666667  \n",
      "18                     5.000000  \n"
     ]
    }
   ],
   "source": [
    "# Function to extract the numerical score from a string\n",
    "def extract_score(value):\n",
    "    try:\n",
    "        return int(str(value).strip().split(':')[-1].strip()) if pd.notnull(value) else None\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Load the data\n",
    "file_path = './정성평가_민혁.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Apply the function to extract scores and convert to numeric\n",
    "cleaned_data = data.applymap(extract_score)\n",
    "\n",
    "# Remove rows with NaN values\n",
    "cleaned_data = cleaned_data.dropna()\n",
    "\n",
    "# Group by every four rows and calculate the mean for each column\n",
    "mean_values_per_column = cleaned_data.groupby(cleaned_data.index // 4).mean()\n",
    "\n",
    "# Reset the index for clean formatting if needed\n",
    "mean_values_per_column.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(mean_values_per_column)"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> 8e228dc73cc39899f044884d150e3e627ac5db4b
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retallm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
