{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('/Project/src/ChatGPT_3.5_주관적_aspect.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_FT_4 = pd.read_csv('/Project/src/ChatGPT_4.0_FT_주관적_aspect.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ChatGPT-3.5  ChatGPT-3.5 +FT-LLM (News)  ChatGPT-3.5 +FT-LLM(News+wiki)  \\\n",
      "0      4.500000                    4.500000                        3.750000   \n",
      "1      1.000000                    1.000000                        1.666667   \n",
      "2      3.333333                    3.333333                        3.333333   \n",
      "3      4.666667                    4.333333                        4.000000   \n",
      "4      4.666667                    3.666667                        3.666667   \n",
      "5      4.750000                    5.000000                        5.000000   \n",
      "6      5.000000                    4.666667                        4.666667   \n",
      "7      2.666667                    2.666667                        2.666667   \n",
      "8      2.666667                    3.000000                        3.333333   \n",
      "9      1.666667                    3.000000                        4.666667   \n",
      "10     4.500000                    4.500000                        4.500000   \n",
      "11     5.000000                    5.000000                        5.000000   \n",
      "12     4.333333                    4.666667                        4.333333   \n",
      "13     4.666667                    4.666667                        4.666667   \n",
      "14     3.000000                    3.666667                        3.666667   \n",
      "15     4.000000                    3.000000                        3.000000   \n",
      "16     4.666667                    4.666667                        4.666667   \n",
      "17     4.000000                    2.000000                        4.333333   \n",
      "18     4.000000                    1.000000                        4.000000   \n",
      "\n",
      "    ChatGPT-3.5 +FT-LLM(News+Confidence)  ChatGPT- 4.0  \\\n",
      "0                               3.000000      4.250000   \n",
      "1                               1.000000      1.000000   \n",
      "2                               3.000000      3.666667   \n",
      "3                               4.666667      5.000000   \n",
      "4                               3.000000      5.000000   \n",
      "5                               4.250000      5.000000   \n",
      "6                               5.000000      5.000000   \n",
      "7                               2.333333      3.000000   \n",
      "8                               2.666667      2.000000   \n",
      "9                               2.666667      1.666667   \n",
      "10                              4.500000      4.500000   \n",
      "11                              5.000000      5.000000   \n",
      "12                              4.333333      4.666667   \n",
      "13                              4.666667      4.333333   \n",
      "14                              3.666667      2.000000   \n",
      "15                              4.500000      4.000000   \n",
      "16                              4.666667      4.666667   \n",
      "17                              4.333333      4.666667   \n",
      "18                              4.000000      5.000000   \n",
      "\n",
      "    ChatGPT- 4.0 + FT-LLM(News)  \n",
      "0                      4.750000  \n",
      "1                      5.000000  \n",
      "2                      4.333333  \n",
      "3                      4.333333  \n",
      "4                      4.666667  \n",
      "5                      3.000000  \n",
      "6                      4.666667  \n",
      "7                      4.666667  \n",
      "8                      5.000000  \n",
      "9                      4.666667  \n",
      "10                     5.000000  \n",
      "11                     5.000000  \n",
      "12                     5.000000  \n",
      "13                     5.000000  \n",
      "14                     4.666667  \n",
      "15                     5.000000  \n",
      "16                     4.666667  \n",
      "17                     4.666667  \n",
      "18                     5.000000  \n"
     ]
    }
   ],
   "source": [
    "# Function to extract the numerical score from a string\n",
    "def extract_score(value):\n",
    "    try:\n",
    "        return int(str(value).strip().split(':')[-1].strip()) if pd.notnull(value) else None\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Load the data\n",
    "file_path = './정성평가_민혁.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Apply the function to extract scores and convert to numeric\n",
    "cleaned_data = data.applymap(extract_score)\n",
    "\n",
    "# Remove rows with NaN values\n",
    "cleaned_data = cleaned_data.dropna()\n",
    "\n",
    "# Group by every four rows and calculate the mean for each column\n",
    "mean_values_per_column = cleaned_data.groupby(cleaned_data.index // 4).mean()\n",
    "\n",
    "# Reset the index for clean formatting if needed\n",
    "mean_values_per_column.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(mean_values_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGPT-3.5                             3.846491\n",
       "ChatGPT-3.5 +FT-LLM (News)              3.596491\n",
       "ChatGPT-3.5 +FT-LLM(News+wiki)          3.942982\n",
       "ChatGPT-3.5 +FT-LLM(News+Confidence)    3.750000\n",
       "ChatGPT- 4.0                            3.916667\n",
       "ChatGPT- 4.0 + FT-LLM(News)             4.688596\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_values_per_column.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChatGPT-3.5</th>\n",
       "      <th>ChatGPT-3.5 +FT-LLM (News)</th>\n",
       "      <th>ChatGPT-3.5 +FT-LLM(News+wiki)</th>\n",
       "      <th>ChatGPT-3.5 +FT-LLM(News+Confidence)</th>\n",
       "      <th>ChatGPT- 4.0</th>\n",
       "      <th>ChatGPT- 4.0 + FT-LLM(News)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ChatGPT-3.5  ChatGPT-3.5 +FT-LLM (News)  ChatGPT-3.5 +FT-LLM(News+wiki)  \\\n",
       "0      4.500000                    4.500000                        3.750000   \n",
       "1      1.000000                    1.000000                        1.666667   \n",
       "2      3.333333                    3.333333                        3.333333   \n",
       "3      4.666667                    4.333333                        4.000000   \n",
       "4      4.666667                    3.666667                        3.666667   \n",
       "5      4.750000                    5.000000                        5.000000   \n",
       "6      5.000000                    4.666667                        4.666667   \n",
       "7      2.666667                    2.666667                        2.666667   \n",
       "8      2.666667                    3.000000                        3.333333   \n",
       "9      1.666667                    3.000000                        4.666667   \n",
       "10     4.500000                    4.500000                        4.500000   \n",
       "11     5.000000                    5.000000                        5.000000   \n",
       "12     4.333333                    4.666667                        4.333333   \n",
       "13     4.666667                    4.666667                        4.666667   \n",
       "14     3.000000                    3.666667                        3.666667   \n",
       "15     4.000000                    3.000000                        3.000000   \n",
       "16     4.666667                    4.666667                        4.666667   \n",
       "17     4.000000                    2.000000                        4.333333   \n",
       "18     4.000000                    1.000000                        4.000000   \n",
       "\n",
       "    ChatGPT-3.5 +FT-LLM(News+Confidence)  ChatGPT- 4.0  \\\n",
       "0                               3.000000      4.250000   \n",
       "1                               1.000000      1.000000   \n",
       "2                               3.000000      3.666667   \n",
       "3                               4.666667      5.000000   \n",
       "4                               3.000000      5.000000   \n",
       "5                               4.250000      5.000000   \n",
       "6                               5.000000      5.000000   \n",
       "7                               2.333333      3.000000   \n",
       "8                               2.666667      2.000000   \n",
       "9                               2.666667      1.666667   \n",
       "10                              4.500000      4.500000   \n",
       "11                              5.000000      5.000000   \n",
       "12                              4.333333      4.666667   \n",
       "13                              4.666667      4.333333   \n",
       "14                              3.666667      2.000000   \n",
       "15                              4.500000      4.000000   \n",
       "16                              4.666667      4.666667   \n",
       "17                              4.333333      4.666667   \n",
       "18                              4.000000      5.000000   \n",
       "\n",
       "    ChatGPT- 4.0 + FT-LLM(News)  \n",
       "0                      4.750000  \n",
       "1                      5.000000  \n",
       "2                      4.333333  \n",
       "3                      4.333333  \n",
       "4                      4.666667  \n",
       "5                      3.000000  \n",
       "6                      4.666667  \n",
       "7                      4.666667  \n",
       "8                      5.000000  \n",
       "9                      4.666667  \n",
       "10                     5.000000  \n",
       "11                     5.000000  \n",
       "12                     5.000000  \n",
       "13                     5.000000  \n",
       "14                     4.666667  \n",
       "15                     5.000000  \n",
       "16                     4.666667  \n",
       "17                     4.666667  \n",
       "18                     5.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_values_per_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mean_values_per_column['ChatGPT- 4.0']<mean_values_per_column['ChatGPT-3.5 +FT-LLM (News)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./객관적.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df['Original Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df['Golden Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_f1(gold_answers, candidate_answer):\n",
    "    \"\"\"\n",
    "    Compute the F1 score for a candidate answer with respect to a set of gold answers.\n",
    "    \n",
    "    Parameters:\n",
    "    - gold_answers (list of str): A list of gold (correct) answers.\n",
    "    - candidate_answer (str): The candidate answer to evaluate.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The maximum F1 score for the candidate answer with respect to the gold answers.\n",
    "    \"\"\"\n",
    "    max_f1 = 0.0\n",
    "    \n",
    "    # Tokenize the candidate answer\n",
    "    candidate_tokens = set(candidate_answer.split())\n",
    "    \n",
    "    for gold_answer in gold_answers:\n",
    "        # Tokenize the gold answer\n",
    "        gold_tokens = set(gold_answer.split())\n",
    "        \n",
    "        # Calculate the number of overlapping tokens\n",
    "        common_tokens = candidate_tokens.intersection(gold_tokens)\n",
    "        \n",
    "        # Compute precision and recall\n",
    "        precision = len(common_tokens) / len(candidate_tokens)\n",
    "        recall = len(common_tokens) / len(gold_tokens)\n",
    "        \n",
    "        # Compute F1 score\n",
    "        if precision + recall == 0:\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        # Update the maximum F1 score\n",
    "        max_f1 = max(max_f1, f1)\n",
    "    \n",
    "    return max_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_f1_list = []\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    response = df[df.columns[i+3]]\n",
    "\n",
    "    f1_score = 0.0\n",
    "    for j in range(len(label)):\n",
    "        try:\n",
    "            gold_answers = [label[j]]\n",
    "            candidate_answer = response[j]\n",
    "            f1 = compute_f1(gold_answers, candidate_answer)\n",
    "        except:\n",
    "            f1 = 0.0\n",
    "            \n",
    "        f1_score+=f1\n",
    "        \n",
    "    avg_f1 = f1_score/len(label)\n",
    "    \n",
    "    avg_f1_list.append(avg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ChatGPT-3.5', 'ChatGPT-3.5 +FT-LLM (News)',\n",
       "       'ChatGPT-3.5 +FT-LLM\\n(News+wiki)',\n",
       "       'ChatGPT-3.5 +FT-LLM\\n(News+Confidence)', 'ChatGPT- 4.0',\n",
       "       'ChatGPT- 4.0 + FT-LLM\\n(News)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027924029274846187,\n",
       " 0.03899884908201792,\n",
       " 0.0327412471872984,\n",
       " 0.0540846637651834,\n",
       " 0.03516970900138079,\n",
       " 0.06696117699902547]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_f1_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acc_Human Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_human_prompt = '''\n",
    "\n",
    "{{#user~}}\n",
    "\n",
    "Question: {{question}}\n",
    "\n",
    "Answer: {{answer}}\n",
    "\n",
    "Candidate: {{candidate}}\n",
    "\n",
    "Is candidate correct? Answer 0 for No and 1 for Yes\n",
    "\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "\n",
    "{{gen \"answer\" max_tokens=1 temperature=0.0 n=1}}\n",
    "\n",
    "{{~/assistant}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [04:25<00:00, 44.29s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import guidance \n",
    "\n",
    "all_model_list = []\n",
    "\n",
    "for i in tqdm(range(6)):\n",
    "    per_model_list = []\n",
    "\n",
    "    for j in range(len(questions)):\n",
    "\n",
    "        llm = guidance.llms.OpenAI(\"gpt-4\", caching=True,\n",
    "                                    api_key = \"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\",\n",
    "                                    ) \n",
    "        guidance.llm = llm \n",
    "\n",
    "        guidance.llm.cache.clear()\n",
    "\n",
    "        structure_program = guidance(acc_human_prompt, \n",
    "                                    question = questions[j], \n",
    "                                    answer = label[j],\n",
    "                                    candidate = df[df.columns[i+3]][j],\n",
    "                                    silent = True\n",
    "                                    )\n",
    "\n",
    "        res = structure_program()\n",
    "\n",
    "        binary_answer = int(res['answer'])\n",
    "        \n",
    "        per_model_list.append(binary_answer)\n",
    "    \n",
    "    all_model_list.append(per_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "binary_list = np.array(all_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = pd.DataFrame(binary_list.T, columns = df.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.to_csv('./ACC_GPT_객관적.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGPT-3.5                               0.500000\n",
       "ChatGPT-3.5 +FT-LLM (News)                0.391304\n",
       "ChatGPT-3.5 +FT-LLM\\n(News+wiki)          0.391304\n",
       "ChatGPT-3.5 +FT-LLM\\n(News+Confidence)    0.565217\n",
       "ChatGPT- 4.0                              0.543478\n",
       "ChatGPT- 4.0 + FT-LLM\\n(News)             0.695652\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df.apply(lambda x: sum(x)/len(x), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./주관적.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ChatGPT-3.5', 'ChatGPT-3.5 +FT-LLM (News)',\n",
       "       'ChatGPT-3.5 +FT-LLM\\n(News+wiki)',\n",
       "       'ChatGPT-3.5 +FT-LLM\\n(News+Confidence)', 'ChatGPT- 4.0',\n",
       "       'ChatGPT- 4.0 + FT-LLM\\n(News)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df['Original Question']\n",
    "reference = df['Human Reference']\n",
    "answers = df[df.columns[3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gpt_prompt = '''\n",
    "{{#user~}}\n",
    "\n",
    "You will be given series of sentences written as a response for football related question.\n",
    " \n",
    "Your task is to rate the summary on one metric.\n",
    "\n",
    "Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\n",
    "\n",
    "Evaluation Criteria:\n",
    "\n",
    "{{aspect}} (1-5) {{aspect_definition}}}\n",
    "\n",
    "Evaluation Steps:\n",
    "\n",
    "1. Read the response carefully and identify the main topic and key points.\n",
    "2. Read the response and compare it to the reference. Check if the response maintains similar tone and context compared to the reference.\n",
    "3. Assign a score for {{aspect}} on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\n",
    "\n",
    "\n",
    "Question\n",
    "{{question}}\n",
    "\n",
    "Reference\n",
    "{{reference}}\n",
    "\n",
    "Answer\n",
    "{{answer}}\n",
    "\n",
    "Score for {{aspect}} (1-5): \n",
    "\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "\n",
    "{{gen \"answer\" max_tokens=1 temperature=0.0 n=1}}\n",
    "\n",
    "{{~/assistant}}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_dict = {\n",
    "    'Factuality' : 'Is the information provided in the response factually grounded?',\n",
    "    'Relevance' : 'How consistent is the content in your answer with the content in the Golden Label?',\n",
    "    'Reasoning' : 'How logical and natural is the content of the answer compared to the Human reference?',\n",
    "    'Interestingness' : 'Does the answer provide interesting or innovative insights or information at a level equivalent to the Human reference?'\n",
    "}\n",
    "\n",
    "aspect_list = ['Factuality', 'Relevance', 'Reasoning', 'Interestingness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-7c62fcd8-7dbd-46a7-8f0a-15254ae577ed\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-7c62fcd8-7dbd-46a7-8f0a-15254ae577ed\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You will be given series of sentences written as a response for football related question.\n",
       " \n",
       "Your task is to rate the summary on one metric.\n",
       "\n",
       "Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\n",
       "\n",
       "Evaluation Criteria:\n",
       "\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{aspect}}'>Interestingness</span> (1-5) <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{aspect_definition}}'>Does the answer provide interesting or innovative insights or information at a level equivalent to the Human reference?</span>}\n",
       "\n",
       "Evaluation Steps:\n",
       "\n",
       "1. Read the response carefully and identify the main topic and key points.\n",
       "2. Read the response and compare it to the reference. Check if the response maintains similar tone and context compared to the reference.\n",
       "3. Assign a score for <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{aspect}}'>Interestingness</span> on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\n",
       "\n",
       "\n",
       "Question\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{question}}'>FIFA 월드컵 예선 기간 동안, 어느 지역(예: 남미, 유럽, 아시아)의 예선 경기가 가장 치열한 경쟁을 가지나요? 그 지역의 주요 팀들 중 누가 가장 큰 경쟁을 겪었나요?</span>\n",
       "\n",
       "Reference\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{reference}}'> 제일 치열한 경쟁이란 팀들간의 실력 편차가 별로 크지 않아 누가 예선을 통과할지 모르는 상황이라고 생각합니다. 그러므로 매번 월드컵에서 본선에 올라오는 팀이 가장 많이 바뀌는 아프리카를 뽑고 싶습니다. 국가 수가 많은 유럽이나 아시아도 본선에 올라오는 팀들은 자주 올라오는 반면, 아프리카는 얼핏 생각해도 빈도가 너무 자주 바뀝니다. \n",
       " 다들 실력이 비슷하여 누가 가장 큰 경쟁을 겪었을까 고르기 쉽지 않지만, 아프리카에서 가장 많이 본선을 진출한 카메룬이 항상 큰 경쟁을 마치고 본선에 진출했으니 제일 치열했다고 생각합니다.. </span>\n",
       "\n",
       "Answer\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{answer}}'>&quot;FIFA 월드컵 예선 기간 동안, 남미 지역의 예선 경기가 가장 치열한 경쟁을 보여주었습니다. 특히 에콰도르는 브라질, 아르헨티나, 우루과이와 같은 강팀들과 치열한 경쟁을 벌였습니다. 에콰도르는 브라질, 아르헨티나에 이어 4위로 지역 예선을 마감했으며, 우루과이와의 승점 차는 단 2점이었습니다. 또한 에콰도르는 월드컵 남미 지역 예선 경기에서 &#x27;부정선수&#x27; 논란을 겪었는데, 콜롬비아 출신의 바이런 카스티요를 그라운드에 내보냈다는 의혹을 받았습니다. 이러한 사항들로 보아, 에콰도르 팀이 가장 큰 경쟁을 겪었다고 볼 수 있습니다.&quot;</span>\n",
       "\n",
       "Score for <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{aspect}}'>Interestingness</span> (1-5):</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &quot;answer&quot; max_tokens=1 temperature=0.0 n=1}}'>3</span></div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"7c62fcd8-7dbd-46a7-8f0a-15254ae577ed\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:29<00:00, 17.93s/it]\n"
     ]
    }
   ],
   "source": [
    "import guidance\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "all_model_list = []\n",
    "per_model_save_list = []\n",
    "\n",
    "for i in range(6):\n",
    "    per_model_list = []\n",
    "    #per_model_save_list = []\n",
    "    \n",
    "    for j in tqdm(range(len(questions))):\n",
    "        \n",
    "        aspect_score = []\n",
    "\n",
    "        for aspect in aspect_list:\n",
    "\n",
    "            llm = guidance.llms.OpenAI(\"gpt-4\", caching=True,\n",
    "                                        api_key = \"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\",\n",
    "                                        ) \n",
    "            guidance.llm = llm \n",
    "\n",
    "            guidance.llm.cache.clear()\n",
    "\n",
    "            try:\n",
    "                structure_program = guidance(eval_gpt_prompt, \n",
    "                                            aspect = aspect,\n",
    "                                            aspect_definition = aspect_dict[aspect],\n",
    "                                            question = questions[j], \n",
    "                                            reference = reference[j],\n",
    "                                            answer = df[df.columns[i+3]][j],\n",
    "                                            silent = False\n",
    "                                            )\n",
    "\n",
    "                res = structure_program()\n",
    "\n",
    "                scaled_answer = int(res['answer'])\n",
    "            \n",
    "            except:\n",
    "                scaled_answer = 3\n",
    "                print('Error')\n",
    "                        \n",
    "            aspect_score.append(scaled_answer)\n",
    "        \n",
    "        per_model_save_list.append(aspect_score)\n",
    "        \n",
    "        final_score = sum(aspect_score)/len(aspect_score)\n",
    "        per_model_list.append(final_score)\n",
    "    \n",
    "    all_model_list.append(per_model_list)\n",
    "    \n",
    "\n",
    "model_score = pd.DataFrame(np.array(all_model_list).T)\n",
    "model_score.columns = df.columns[3:]\n",
    "model_score.to_csv(f'./주관적_total.csv', index = False)\n",
    "\n",
    "per_model_save_list = np.array(per_model_save_list).reshape(6,15,4)\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    temp_df = pd.DataFrame(per_model_save_list[i])\n",
    "    temp_df.columns = aspect_list\n",
    "    file_name = df.columns[3:][i]\n",
    "    temp_df.to_csv(f'./{file_name}_주관적_aspect.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retallm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
